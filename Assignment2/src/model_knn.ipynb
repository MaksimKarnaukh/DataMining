{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:58:14.954831800Z",
     "start_time": "2024-04-29T03:58:13.689536600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'ot': ot_distance will be unavailable. To install, run:\n",
      "pip install 'aif360[OptimalTransport]'\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from typing import List, Tuple\n",
    "from helper.helper_functions import load_dataset, save_model, get_features_and_target, encode_all_features\n",
    "from helper.clfmodel_functions import tune_model, seq_feat_selection, multi_metric_cv, plot_multi_score_cv_results, forward_feat_selection_hypertuning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the cleaned dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ced45577f2a46d2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = load_dataset('../data/assignment2_income_cleaned.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:58:17.149957Z",
     "start_time": "2024-04-29T03:58:14.956702800Z"
    }
   },
   "id": "573b15a0c08becd2",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Engineering (encoding) & Train-Test Split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98bf0f84f262caa7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Splitting the data into features (X) and target (y)\n",
    "X, y = get_features_and_target(data, 'income')\n",
    "columns_to_exclude = ['age', 'ability to speak english', 'gave birth this year']\n",
    "# Encoding the features and target\n",
    "X_encoded, y_encoded = encode_all_features(X, y, [])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:58:17.178720400Z",
     "start_time": "2024-04-29T03:58:17.151952300Z"
    }
   },
   "id": "83fc7449a1cf23ea",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      age  education  workinghours  ability to speak english  \\\n6317   22         16            36                         0   \n740    61         22            40                         1   \n3781   48         16            40                         0   \n7850   62         18            65                         0   \n2963   53         19            44                         0   \n\n      workclass_governmental  workclass_no paid work  workclass_private  \\\n6317                       0                       0                  1   \n740                        0                       0                  0   \n3781                       0                       0                  1   \n7850                       0                       0                  1   \n2963                       1                       0                  0   \n\n      workclass_self employed  marital status_Divorced  \\\n6317                        0                        0   \n740                         1                        1   \n3781                        0                        1   \n7850                        0                        0   \n2963                        0                        1   \n\n      marital status_Husband  ...  occupation_Office/Administrative Support  \\\n6317                       1  ...                                         0   \n740                        0  ...                                         0   \n3781                       0  ...                                         1   \n7850                       1  ...                                         0   \n2963                       0  ...                                         1   \n\n      occupation_Production/Assembly  occupation_Protective Services  \\\n6317                               1                               0   \n740                                0                               0   \n3781                               0                               0   \n7850                               1                               0   \n2963                               0                               0   \n\n      occupation_Repair/Maintenance  occupation_Sales  \\\n6317                              0                 0   \n740                               0                 1   \n3781                              0                 0   \n7850                              0                 0   \n2963                              0                 0   \n\n      occupation_Science, Engineering, Technology  \\\n6317                                            0   \n740                                             0   \n3781                                            0   \n7850                                            0   \n2963                                            0   \n\n      occupation_Service/Hospitality  occupation_Transport  \\\n6317                               0                     0   \n740                                0                     0   \n3781                               0                     0   \n7850                               0                     0   \n2963                               0                     0   \n\n      gave birth this year_No  gave birth this year_Yes  \n6317                        1                         0  \n740                         1                         0  \n3781                        1                         0  \n7850                        1                         0  \n2963                        1                         0  \n\n[5 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>education</th>\n      <th>workinghours</th>\n      <th>ability to speak english</th>\n      <th>workclass_governmental</th>\n      <th>workclass_no paid work</th>\n      <th>workclass_private</th>\n      <th>workclass_self employed</th>\n      <th>marital status_Divorced</th>\n      <th>marital status_Husband</th>\n      <th>...</th>\n      <th>occupation_Office/Administrative Support</th>\n      <th>occupation_Production/Assembly</th>\n      <th>occupation_Protective Services</th>\n      <th>occupation_Repair/Maintenance</th>\n      <th>occupation_Sales</th>\n      <th>occupation_Science, Engineering, Technology</th>\n      <th>occupation_Service/Hospitality</th>\n      <th>occupation_Transport</th>\n      <th>gave birth this year_No</th>\n      <th>gave birth this year_Yes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6317</th>\n      <td>22</td>\n      <td>16</td>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>740</th>\n      <td>61</td>\n      <td>22</td>\n      <td>40</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3781</th>\n      <td>48</td>\n      <td>16</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7850</th>\n      <td>62</td>\n      <td>18</td>\n      <td>65</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2963</th>\n      <td>53</td>\n      <td>19</td>\n      <td>44</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:58:17.201659600Z",
     "start_time": "2024-04-29T03:58:17.172736600Z"
    }
   },
   "id": "32090237fac6568d",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model\n",
    "\n",
    "Here, we quickly train and evaluate a KNN model with random parameters for demonstration."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfc5f29026270e84"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1175\n",
      "           1       0.62      0.62      0.62       625\n",
      "\n",
      "    accuracy                           0.73      1800\n",
      "   macro avg       0.71      0.71      0.71      1800\n",
      "weighted avg       0.74      0.73      0.74      1800\n",
      "\n",
      "K-Nearest Neighbors Accuracy: 0.735\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_preds = knn_model.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_preds)\n",
    "\n",
    "print(classification_report(y_test, knn_preds))\n",
    "print(\"K-Nearest Neighbors Accuracy:\", knn_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:58:17.951110Z",
     "start_time": "2024-04-29T03:58:17.200661400Z"
    }
   },
   "id": "7e89004d3b62eb17",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Importance using the model itself"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edf60206d423aab1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if False:\n",
    "    seq_feat_selection(KNeighborsClassifier(), X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:58:17.954237200Z",
     "start_time": "2024-04-29T03:58:17.941859600Z"
    }
   },
   "id": "c0c47f5934a16da",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1951416f12714f18"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we define the base parameter grid for our hyperparameter tuning function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30ed8892bbf4a434"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'n_neighbors': np.arange(2, 31, 1),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T03:58:17.960218500Z",
     "start_time": "2024-04-29T03:58:17.947121200Z"
    }
   },
   "id": "ade690f102ffb74b",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below, we tune the hyperparameters of the KNN model using the defined parameter grid and using all features."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfbd1effd8fb2744"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Best Hyperparameters: {'n_neighbors': 22, 'p': 1, 'weights': 'uniform'}\n",
      "Best Model: KNeighborsClassifier(n_neighbors=22, p=1)\n",
      "Best Model Accuracy: 0.7605555555555555\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    best_params, best_model, best_accuracy = tune_model(KNeighborsClassifier(), X_train, y_train, X_test, y_test, param_grid, top_n=10)\n",
    "    \n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Model:\", best_model)\n",
    "    print(\"Best Model Accuracy:\", best_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T04:01:02.094147400Z",
     "start_time": "2024-04-29T03:58:17.958224100Z"
    }
   },
   "id": "c7365ea88fe88b3a",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Best Hyperparameters: {'n_neighbors': 30, 'p': 2, 'weights': 'uniform'}\n",
      "Best Model: KNeighborsClassifier(n_neighbors=30)\n",
      "Best Model Composite Score: 0.7912730130961485\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    best_params, best_model, best_composite_metric = tune_model(KNeighborsClassifier(), X_train, y_train, X_test, y_test, param_grid, top_n=10, ensure_fairness=True)\n",
    "    \n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Model:\", best_model)\n",
    "    print(\"Best Model Composite Score:\", best_composite_metric)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T04:04:08.203244700Z",
     "start_time": "2024-04-29T04:01:02.089160300Z"
    }
   },
   "id": "38f9828092b9f729",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below, we tune the hyperparameters of the KNN model using the defined parameter grid and using a **subset of features**. We exclude the columns 'age', 'ability to speak english', and 'workclass'."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf25caeb313e2bd5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "\n",
      "Best Hyperparameters: {'n_neighbors': 27, 'p': 1, 'weights': 'uniform'}\n",
      "Best Model: KNeighborsClassifier(n_neighbors=27, p=1)\n",
      "Best Model Accuracy: 0.7738888888888888\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    # Splitting the data into features (X) and target (y)\n",
    "    X_, y_ = get_features_and_target(data, 'income')\n",
    "    columns_to_exclude = ['age', 'ability to speak english', 'workclass']\n",
    "    X_ = X_.drop(columns=columns_to_exclude)\n",
    "    # Encoding the features and target, and excluding some columns\n",
    "    X_encoded_, y_encoded_ = encode_all_features(X_, y_, columns_to_exclude)\n",
    "    X_train_, X_test_, y_train_, y_test_ = train_test_split(X_encoded_, y_encoded_, test_size=0.2, random_state=42)\n",
    "    \n",
    "    best_params, best_model, best_accuracy = tune_model(KNeighborsClassifier(), X_train_, y_train_, X_test_, y_test_, param_grid)\n",
    "    \n",
    "    print(\"\\nBest Hyperparameters:\", best_params)\n",
    "    print(\"Best Model:\", best_model)\n",
    "    print(\"Best Model Accuracy:\", best_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T04:06:34.736402500Z",
     "start_time": "2024-04-29T04:04:08.200253100Z"
    }
   },
   "id": "ab3c4b22bbcf01e1",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Best subset: ['education']\n",
      "Remaining features: [['age'], ['workinghours'], ['ability to speak english'], ['workclass_governmental', 'workclass_no paid work', 'workclass_private', 'workclass_self employed'], ['marital status_Divorced', 'marital status_Husband', 'marital status_Never married', 'marital status_Separated', 'marital status_Widowed', 'marital status_Wife'], ['occupation_Construction/Extraction', 'occupation_Counseling/Mental Health Services', 'occupation_Education', 'occupation_Entertainment', 'occupation_Farming, Fishing, Forestry', 'occupation_Finance/Accounting', 'occupation_Healthcare/Medical Services', 'occupation_Legal Services', 'occupation_Management/Business', 'occupation_Military Services', 'occupation_Office/Administrative Support', 'occupation_Production/Assembly', 'occupation_Protective Services', 'occupation_Repair/Maintenance', 'occupation_Sales', 'occupation_Science, Engineering, Technology', 'occupation_Service/Hospitality', 'occupation_Transport'], ['sex_Female', 'sex_Male'], ['gave birth this year_No', 'gave birth this year_Yes']]\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Best subset: ['education', 'marital status_Divorced', 'marital status_Husband', 'marital status_Never married', 'marital status_Separated', 'marital status_Widowed', 'marital status_Wife']\n",
      "Remaining features: [['age'], ['workinghours'], ['ability to speak english'], ['workclass_governmental', 'workclass_no paid work', 'workclass_private', 'workclass_self employed'], ['occupation_Construction/Extraction', 'occupation_Counseling/Mental Health Services', 'occupation_Education', 'occupation_Entertainment', 'occupation_Farming, Fishing, Forestry', 'occupation_Finance/Accounting', 'occupation_Healthcare/Medical Services', 'occupation_Legal Services', 'occupation_Management/Business', 'occupation_Military Services', 'occupation_Office/Administrative Support', 'occupation_Production/Assembly', 'occupation_Protective Services', 'occupation_Repair/Maintenance', 'occupation_Sales', 'occupation_Science, Engineering, Technology', 'occupation_Service/Hospitality', 'occupation_Transport'], ['sex_Female', 'sex_Male'], ['gave birth this year_No', 'gave birth this year_Yes']]\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Best subset: ['education', 'marital status_Divorced', 'marital status_Husband', 'marital status_Never married', 'marital status_Separated', 'marital status_Widowed', 'marital status_Wife', 'workinghours']\n",
      "Remaining features: [['age'], ['ability to speak english'], ['workclass_governmental', 'workclass_no paid work', 'workclass_private', 'workclass_self employed'], ['occupation_Construction/Extraction', 'occupation_Counseling/Mental Health Services', 'occupation_Education', 'occupation_Entertainment', 'occupation_Farming, Fishing, Forestry', 'occupation_Finance/Accounting', 'occupation_Healthcare/Medical Services', 'occupation_Legal Services', 'occupation_Management/Business', 'occupation_Military Services', 'occupation_Office/Administrative Support', 'occupation_Production/Assembly', 'occupation_Protective Services', 'occupation_Repair/Maintenance', 'occupation_Sales', 'occupation_Science, Engineering, Technology', 'occupation_Service/Hospitality', 'occupation_Transport'], ['sex_Female', 'sex_Male'], ['gave birth this year_No', 'gave birth this year_Yes']]\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Best subset: ['education', 'marital status_Divorced', 'marital status_Husband', 'marital status_Never married', 'marital status_Separated', 'marital status_Widowed', 'marital status_Wife', 'workinghours', 'occupation_Construction/Extraction', 'occupation_Counseling/Mental Health Services', 'occupation_Education', 'occupation_Entertainment', 'occupation_Farming, Fishing, Forestry', 'occupation_Finance/Accounting', 'occupation_Healthcare/Medical Services', 'occupation_Legal Services', 'occupation_Management/Business', 'occupation_Military Services', 'occupation_Office/Administrative Support', 'occupation_Production/Assembly', 'occupation_Protective Services', 'occupation_Repair/Maintenance', 'occupation_Sales', 'occupation_Science, Engineering, Technology', 'occupation_Service/Hospitality', 'occupation_Transport']\n",
      "Remaining features: [['age'], ['ability to speak english'], ['workclass_governmental', 'workclass_no paid work', 'workclass_private', 'workclass_self employed'], ['sex_Female', 'sex_Male'], ['gave birth this year_No', 'gave birth this year_Yes']]\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Best subset: ['education', 'marital status_Divorced', 'marital status_Husband', 'marital status_Never married', 'marital status_Separated', 'marital status_Widowed', 'marital status_Wife', 'workinghours', 'occupation_Construction/Extraction', 'occupation_Counseling/Mental Health Services', 'occupation_Education', 'occupation_Entertainment', 'occupation_Farming, Fishing, Forestry', 'occupation_Finance/Accounting', 'occupation_Healthcare/Medical Services', 'occupation_Legal Services', 'occupation_Management/Business', 'occupation_Military Services', 'occupation_Office/Administrative Support', 'occupation_Production/Assembly', 'occupation_Protective Services', 'occupation_Repair/Maintenance', 'occupation_Sales', 'occupation_Science, Engineering, Technology', 'occupation_Service/Hospitality', 'occupation_Transport', 'gave birth this year_No', 'gave birth this year_Yes']\n",
      "Remaining features: [['age'], ['ability to speak english'], ['workclass_governmental', 'workclass_no paid work', 'workclass_private', 'workclass_self employed'], ['sex_Female', 'sex_Male']]\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Fitting 5 folds for each of 116 candidates, totalling 580 fits\n",
      "Best subset: ['education', 'marital status_Divorced', 'marital status_Husband', 'marital status_Never married', 'marital status_Separated', 'marital status_Widowed', 'marital status_Wife', 'workinghours', 'occupation_Construction/Extraction', 'occupation_Counseling/Mental Health Services', 'occupation_Education', 'occupation_Entertainment', 'occupation_Farming, Fishing, Forestry', 'occupation_Finance/Accounting', 'occupation_Healthcare/Medical Services', 'occupation_Legal Services', 'occupation_Management/Business', 'occupation_Military Services', 'occupation_Office/Administrative Support', 'occupation_Production/Assembly', 'occupation_Protective Services', 'occupation_Repair/Maintenance', 'occupation_Sales', 'occupation_Science, Engineering, Technology', 'occupation_Service/Hospitality', 'occupation_Transport', 'gave birth this year_No', 'gave birth this year_Yes']\n",
      "Remaining features: [['age'], ['ability to speak english'], ['workclass_governmental', 'workclass_no paid work', 'workclass_private', 'workclass_self employed'], ['sex_Female', 'sex_Male']]\n",
      "Best subset of features: ['education', 'marital status_Divorced', 'marital status_Husband', 'marital status_Never married', 'marital status_Separated', 'marital status_Widowed', 'marital status_Wife', 'workinghours', 'occupation_Construction/Extraction', 'occupation_Counseling/Mental Health Services', 'occupation_Education', 'occupation_Entertainment', 'occupation_Farming, Fishing, Forestry', 'occupation_Finance/Accounting', 'occupation_Healthcare/Medical Services', 'occupation_Legal Services', 'occupation_Management/Business', 'occupation_Military Services', 'occupation_Office/Administrative Support', 'occupation_Production/Assembly', 'occupation_Protective Services', 'occupation_Repair/Maintenance', 'occupation_Sales', 'occupation_Science, Engineering, Technology', 'occupation_Service/Hospitality', 'occupation_Transport', 'gave birth this year_No', 'gave birth this year_Yes']\n",
      "Best hyperparameters: {'n_neighbors': 27, 'p': 1, 'weights': 'uniform'}\n",
      "Best model accuracy: 0.7827777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1175\n",
      "           1       0.69      0.65      0.67       625\n",
      "\n",
      "    accuracy                           0.78      1800\n",
      "   macro avg       0.75      0.75      0.75      1800\n",
      "weighted avg       0.77      0.78      0.77      1800\n"
     ]
    }
   ],
   "source": [
    "# Forward feature selection with hyperparameter tuning\n",
    "if True:\n",
    "    best_subset, best_params, best_score = forward_feat_selection_hypertuning(KNeighborsClassifier(), param_grid, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(\"Best subset of features:\", best_subset)\n",
    "    print(\"Best hyperparameters:\", best_params)\n",
    "    print(\"Best model accuracy:\", best_score)\n",
    "    \n",
    "    # Use the best subset and best hyperparameters for final model\n",
    "    final_model = KNeighborsClassifier(**best_params)\n",
    "    final_model.fit(X_train[best_subset], y_train)\n",
    "    final_model_preds = final_model.predict(X_test[best_subset])\n",
    "    final_model_accuracy = accuracy_score(y_test, final_model_preds)\n",
    "    \n",
    "    print(classification_report(y_test, final_model_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T04:56:34.900641500Z",
     "start_time": "2024-04-29T04:06:34.730418900Z"
    }
   },
   "id": "ef0a2ac8b804d296",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"F:\\PyCharmProjects\\DataMining\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"F:\\PyCharmProjects\\DataMining\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"F:\\PyCharmProjects\\DataMining\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 149, in fit\n    self._validate_estimator()\n  File \"F:\\PyCharmProjects\\DataMining\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 537, in _validate_estimator\n    raise ValueError(\nValueError: KNeighborsClassifier doesn't support sample_weight.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 10\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Define the parameter grid for AdaBoost\u001B[39;00m\n\u001B[0;32m      2\u001B[0m param_grid \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124malgorithm\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSAMME\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSAMME.R\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_estimators\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m50\u001B[39m, \u001B[38;5;241m75\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m150\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrandom_state\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m42\u001B[39m]\n\u001B[0;32m      8\u001B[0m }\n\u001B[1;32m---> 10\u001B[0m best_params, best_model, best_accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mtune_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mAdaBoostClassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mBest Hyperparameters:\u001B[39m\u001B[38;5;124m\"\u001B[39m, best_params)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest Model:\u001B[39m\u001B[38;5;124m\"\u001B[39m, best_model)\n",
      "File \u001B[1;32mF:\\PyCharmProjects\\DataMining\\Assignment2\\src\\helper\\clfmodel_functions.py:61\u001B[0m, in \u001B[0;36mtune_model\u001B[1;34m(model, X_train, y_train, X_test, y_test, param_grid, top_n, cv, ensure_fairness)\u001B[0m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;66;03m# Perform grid search with 5-fold cross-validation\u001B[39;00m\n\u001B[0;32m     60\u001B[0m gscv: GridSearchCV \u001B[38;5;241m=\u001B[39m GridSearchCV(model, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, cv\u001B[38;5;241m=\u001B[39mcv, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 61\u001B[0m \u001B[43mgscv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     63\u001B[0m top_n_results_idx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margsort(gscv\u001B[38;5;241m.\u001B[39mcv_results_[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean_test_score\u001B[39m\u001B[38;5;124m'\u001B[39m])[\u001B[38;5;241m-\u001B[39mtop_n:]\n\u001B[0;32m     65\u001B[0m best_params: \u001B[38;5;28mdict\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m()\n",
      "File \u001B[1;32mF:\\PyCharmProjects\\DataMining\\.venv\\Lib\\site-packages\\sklearn\\base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1472\u001B[0m     )\n\u001B[0;32m   1473\u001B[0m ):\n\u001B[1;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\PyCharmProjects\\DataMining\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    964\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    965\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    966\u001B[0m     )\n\u001B[0;32m    968\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 970\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    974\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32mF:\\PyCharmProjects\\DataMining\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1525\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1526\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1527\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\PyCharmProjects\\DataMining\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:947\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    940\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m!=\u001B[39m n_candidates \u001B[38;5;241m*\u001B[39m n_splits:\n\u001B[0;32m    941\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    942\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcv.split and cv.get_n_splits returned \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    943\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minconsistent results. Expected \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    944\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplits, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(n_splits, \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m n_candidates)\n\u001B[0;32m    945\u001B[0m     )\n\u001B[1;32m--> 947\u001B[0m \u001B[43m_warn_or_raise_about_fit_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    949\u001B[0m \u001B[38;5;66;03m# For callable self.scoring, the return type is only know after\u001B[39;00m\n\u001B[0;32m    950\u001B[0m \u001B[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001B[39;00m\n\u001B[0;32m    951\u001B[0m \u001B[38;5;66;03m# can now be inserted with the correct key. The type checking\u001B[39;00m\n\u001B[0;32m    952\u001B[0m \u001B[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001B[39;00m\n\u001B[0;32m    953\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring):\n",
      "File \u001B[1;32mF:\\PyCharmProjects\\DataMining\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:536\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[1;34m(results, error_score)\u001B[0m\n\u001B[0;32m    529\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_failed_fits \u001B[38;5;241m==\u001B[39m num_fits:\n\u001B[0;32m    530\u001B[0m     all_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    531\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAll the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    532\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is very likely that your model is misconfigured.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    533\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can try to debug the error by setting error_score=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    534\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    535\u001B[0m     )\n\u001B[1;32m--> 536\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(all_fits_failed_message)\n\u001B[0;32m    538\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    539\u001B[0m     some_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    540\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnum_failed_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed out of a total of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    541\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score on these train-test partitions for these parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    545\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    546\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: \nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"F:\\PyCharmProjects\\DataMining\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"F:\\PyCharmProjects\\DataMining\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"F:\\PyCharmProjects\\DataMining\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 149, in fit\n    self._validate_estimator()\n  File \"F:\\PyCharmProjects\\DataMining\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 537, in _validate_estimator\n    raise ValueError(\nValueError: KNeighborsClassifier doesn't support sample_weight.\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for AdaBoost\n",
    "param_grid = {\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "    'n_estimators': [50, 75, 100, 150],\n",
    "    'learning_rate': [0.1, 0.5, 1.0],\n",
    "    'estimator': [final_model, KNeighborsClassifier()],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "best_params, best_model, best_accuracy = tune_model(AdaBoostClassifier(), X_train, y_train, X_test, y_test, param_grid)\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n",
    "print(\"Best Model:\", best_model)\n",
    "print(\"Best Model Accuracy:\", best_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T04:56:37.700711700Z",
     "start_time": "2024-04-29T04:56:34.897650300Z"
    }
   },
   "id": "66f26b5326c94f2b",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Define the scorers\n",
    "    scoring = {\"AUC\": \"roc_auc\", \"Accuracy\": make_scorer(accuracy_score)}\n",
    "    \n",
    "    n_neighbours_param_min = 2\n",
    "    n_neighbours_param_max = 31\n",
    "    param_grid = {\"n_neighbors\": range(n_neighbours_param_min, n_neighbours_param_max, 1)}\n",
    "\n",
    "    results = multi_metric_cv(KNeighborsClassifier(p=2), scoring, X_train, y_train, param_grid)\n",
    "    plot_multi_score_cv_results(\"n_neighbors\", n_neighbours_param_min, n_neighbours_param_max, 0.7, 1, results, \"param_n_neighbors\", int, scoring)\n",
    "    \n",
    "    results = multi_metric_cv(KNeighborsClassifier(p=1), scoring, X_train, y_train, param_grid)\n",
    "    plot_multi_score_cv_results(\"n_neighbors\", n_neighbours_param_min, n_neighbours_param_max, 0.7, 1, results, \"param_n_neighbors\", int, scoring)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-29T04:56:37.695725500Z"
    }
   },
   "id": "4a3cbc8d13122075"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feature Selection: Ensure that sensitive attributes such as sex are not included as features in the model. This helps prevent the model from directly learning discriminatory patterns based on sensitive attributes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca92285d6580a173"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fair Representation: Balance the representation of different groups within the dataset. Ensure that the dataset is representative of the population with respect to sex and other sensitive attributes. This can help mitigate bias in the model's predictions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "629aa7c9a8929a30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fair Preprocessing: Apply preprocessing techniques that aim to mitigate bias in the dataset. For example, use techniques such as reweighting or resampling to balance the dataset with respect to sensitive attributes.\n",
    "\n",
    "Reweighing:\n",
    "Adjust the weights of instances in your dataset to balance the impact of different groups.\n",
    "Assign higher weights to underrepresented groups (e.g., females) and lower weights to overrepresented groups (e.g., males).\n",
    "This helps reduce bias during model training.\n",
    "Suppression:\n",
    "Remove or suppress the sensitive attribute (‘sex’) from the dataset.\n",
    "Train your model without using this attribute.\n",
    "Note that this approach may lead to information loss, so use it cautiously.\n",
    "Massaging the Dataset:\n",
    "Modify class labels to achieve fairness.\n",
    "For instance, you can swap the labels for different groups (e.g., relabel some ‘male’ instances as ‘female’ and vice versa).\n",
    "This ensures that the model does not learn discriminatory patterns based on the sensitive attribute.\n",
    "Resampling Techniques:\n",
    "Oversample the underrepresented group (e.g., females) or undersample the overrepresented group (e.g., males).\n",
    "This balances the class distribution and reduces bias.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1f7bc109c2e2782"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model Evaluation: Evaluate the model's performance and fairness across different subgroups defined by sensitive attributes such as sex. Use metrics such as disparate impact ratio, equal opportunity difference, or predictive parity to assess fairness."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a61e1afff765d7f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving the Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2b8808539140c16"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "save_model(final_model, '../output/saved_models/knn_model.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-29T04:56:37.697720Z"
    }
   },
   "id": "6a153de59eafb6a6",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
