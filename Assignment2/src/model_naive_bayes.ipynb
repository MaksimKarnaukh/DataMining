{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:41.346858400Z",
     "start_time": "2024-04-29T01:06:41.105183400Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from helper.helper_functions import load_dataset, save_model, get_features_and_target, encode_all_features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from mixed_naive_bayes import MixedNB # https://pypi.org/project/mixed-naive-bayes/#api-documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the cleaned dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ced45577f2a46d2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = load_dataset('../data/assignment2_income_cleaned.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.069910100Z",
     "start_time": "2024-04-29T01:06:41.349850200Z"
    }
   },
   "id": "573b15a0c08becd2",
   "execution_count": 79
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Engineering (encoding) & Train-Test Split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7592687113789b2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Splitting the data into features (X) and target (y)\n",
    "X, y = get_features_and_target(data, 'income')\n",
    "# Encoding the features and target, and excluding some columns\n",
    "X_encoded, y_encoded = encode_all_features(X, y, [])\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.112909400Z",
     "start_time": "2024-04-29T01:06:45.067915700Z"
    }
   },
   "id": "6aef9cfa1cf6ddd3",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      age  education  workinghours  ability to speak english  \\\n6317   22         16            36                         0   \n740    61         22            40                         1   \n3781   48         16            40                         0   \n7850   62         18            65                         0   \n2963   53         19            44                         0   \n\n      occupation_Construction/Extraction  \\\n6317                                   0   \n740                                    0   \n3781                                   0   \n7850                                   0   \n2963                                   0   \n\n      occupation_Counseling/Mental Health Services  occupation_Education  \\\n6317                                             0                     0   \n740                                              0                     0   \n3781                                             0                     0   \n7850                                             0                     0   \n2963                                             0                     0   \n\n      occupation_Entertainment  occupation_Farming, Fishing, Forestry  \\\n6317                         0                                      0   \n740                          0                                      0   \n3781                         0                                      0   \n7850                         0                                      0   \n2963                         0                                      0   \n\n      occupation_Finance/Accounting  ...  sex_Female  sex_Male  \\\n6317                              0  ...           0         1   \n740                               0  ...           0         1   \n3781                              0  ...           1         0   \n7850                              0  ...           0         1   \n2963                              0  ...           1         0   \n\n      marital status_Divorced  marital status_Husband  \\\n6317                        0                       1   \n740                         1                       0   \n3781                        1                       0   \n7850                        0                       1   \n2963                        1                       0   \n\n      marital status_Never married  marital status_Separated  \\\n6317                             0                         0   \n740                              0                         0   \n3781                             0                         0   \n7850                             0                         0   \n2963                             0                         0   \n\n      marital status_Widowed  marital status_Wife  gave birth this year_No  \\\n6317                       0                    0                        1   \n740                        0                    0                        1   \n3781                       0                    0                        1   \n7850                       0                    0                        1   \n2963                       0                    0                        1   \n\n      gave birth this year_Yes  \n6317                         0  \n740                          0  \n3781                         0  \n7850                         0  \n2963                         0  \n\n[5 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>education</th>\n      <th>workinghours</th>\n      <th>ability to speak english</th>\n      <th>occupation_Construction/Extraction</th>\n      <th>occupation_Counseling/Mental Health Services</th>\n      <th>occupation_Education</th>\n      <th>occupation_Entertainment</th>\n      <th>occupation_Farming, Fishing, Forestry</th>\n      <th>occupation_Finance/Accounting</th>\n      <th>...</th>\n      <th>sex_Female</th>\n      <th>sex_Male</th>\n      <th>marital status_Divorced</th>\n      <th>marital status_Husband</th>\n      <th>marital status_Never married</th>\n      <th>marital status_Separated</th>\n      <th>marital status_Widowed</th>\n      <th>marital status_Wife</th>\n      <th>gave birth this year_No</th>\n      <th>gave birth this year_Yes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6317</th>\n      <td>22</td>\n      <td>16</td>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>740</th>\n      <td>61</td>\n      <td>22</td>\n      <td>40</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3781</th>\n      <td>48</td>\n      <td>16</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7850</th>\n      <td>62</td>\n      <td>18</td>\n      <td>65</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2963</th>\n      <td>53</td>\n      <td>19</td>\n      <td>44</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 36 columns</p>\n</div>"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.117667300Z",
     "start_time": "2024-04-29T01:06:45.097949100Z"
    }
   },
   "id": "495ea34f27ff398f",
   "execution_count": 81
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model\n",
    "\n",
    "Here, we quickly train and evaluate a Gaussian Naive Bayes model for demonstration."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfc5f29026270e84"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.78      1175\n",
      "           1       0.58      0.71      0.64       625\n",
      "\n",
      "    accuracy                           0.72      1800\n",
      "   macro avg       0.70      0.72      0.71      1800\n",
      "weighted avg       0.74      0.72      0.73      1800\n",
      "\n",
      "Naive Bayes Accuracy: 0.7227777777777777\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes model (Gaussian)\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_preds = nb_model.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_preds)\n",
    "\n",
    "print(classification_report(y_test, nb_preds))\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.245990100Z",
     "start_time": "2024-04-29T01:06:45.120658600Z"
    }
   },
   "id": "7c4fcfd7603fcff1",
   "execution_count": 82
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combined Naive Bayes Model: Custom Implementation\n",
    "\n",
    "Below we implement and train a Combined Naive Bayes model for mixed data types (categorical and numerical)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "595fb7cd421a19ff"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "\n",
    "class CombinedNB:\n",
    "    \"\"\"\n",
    "    Combined Naive Bayes model for mixed data types (categorical and numerical)\n",
    "    This looks a bit like a sklearn classifier class, but it's not (it doesn't inherit from anything). It's just a simple class that implements the fit and predict methods only, for two combined Naive Bayes models.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_feat: List[str], cat_model: CategoricalNB = CategoricalNB(), num_model: GaussianNB = GaussianNB()):\n",
    "        self.cat_model: CategoricalNB = cat_model\n",
    "        self.num_model: GaussianNB = num_model\n",
    "        self.num_feat: List[str] = num_feat # numerical features\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit the combined model to the training data. We fit the categorical model to the categorical features and the numerical model to the numerical features.\n",
    "        :param X_train: training dataset with mixed features\n",
    "        :param y_train: training dataset with target variable\n",
    "        :return: \n",
    "        \"\"\"\n",
    "        # Splitting data into categorical and numerical features\n",
    "        X_train_cat = X_train.drop(columns=self.num_feat)\n",
    "        X_train_num = X_train[self.num_feat]\n",
    "\n",
    "        self.cat_model.fit(X_train_cat, y_train)\n",
    "        self.num_model.fit(X_train_num, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict the target variable for the test data.\n",
    "        \n",
    "        We use the formula: \n",
    "        P(Class | C1, ..., Cn, N1, ..., Nm) ~= Mult{1, n}(P(Ci | Class)) * Mult{1, m}(P(Nj | Class)) * P(Class)\n",
    "        \n",
    "        where Ci are the categorical features, Nj are the numerical features, and Class is the target variable. \n",
    "        Concerning the scores, we get the following:\n",
    "        Cat * Num * Prior = (Score_cat * Score_num) / Prior\n",
    "\n",
    "        Note: CategoricalNB uses Laplace smoothing by default.\n",
    "        \n",
    "        :param X_test: test dataset with mixed features\n",
    "        :return: predicted target variable\n",
    "        \"\"\"\n",
    "        cat_probs = self.cat_model.predict_proba(X_test.drop(columns=self.num_feat))\n",
    "        num_probs = self.num_model.predict_proba(X_test[self.num_feat])\n",
    "        combined_probs = (cat_probs * num_probs) / self.num_model.class_prior_\n",
    "        # combined_probs /= combined_probs.sum(axis=1, keepdims=True) # normalize the probabilities\n",
    "        return np.argmax(combined_probs, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.313681Z",
     "start_time": "2024-04-29T01:06:45.202753200Z"
    }
   },
   "id": "33c11ade77e2c784",
   "execution_count": 83
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Testing the Combined Naive Bayes Model\n",
    "\n",
    "Below is a small test function for the Combined Naive Bayes model. We will test the model on a small dataset to check if it's generally working correctly. The test is based on the example from the lecture slides by Toon Calders."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfe2fdcca4589a97"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test_combined_nb_model(print_mapping=False):\n",
    "    data_ = {\n",
    "    'Refund': ['Yes', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No'],\n",
    "    'Marital Status': ['Single', 'Married', 'Single', 'Married', 'Divorced', 'Married', 'Divorced', 'Single', 'Married', 'Single', 'Divorced'],\n",
    "    'Taxable Income': [125, 100, 70, 120, 95, 60, 220, 85, 75, 90, 120],\n",
    "    'Evade': ['No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No']\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data_)\n",
    "    \n",
    "    # Encoding features and target\n",
    "    le_ = LabelEncoder()\n",
    "    for col in df.columns:\n",
    "        if col not in ['Taxable Income']:\n",
    "            enc = le_.fit_transform(df[col])\n",
    "            df[col] = enc\n",
    "            # print encoding mapping\n",
    "            if print_mapping:\n",
    "                print(f\"Mapping for {col}:\")\n",
    "                for original, encoded in zip(le_.classes_, range(len(le_.classes_))):\n",
    "                    print(f\"{original} -> {encoded}\")\n",
    "    \n",
    "    # Separate features (X) and target variable (y)\n",
    "    X_ = df.iloc[:, :-1]\n",
    "    y_ = df.iloc[:, -1]\n",
    "    \n",
    "    # Splitting data into training and test sets\n",
    "    X_train_ = X_.iloc[:-1]\n",
    "    X_test_ = X_.iloc[-1:]\n",
    "    y_train_ = y_.iloc[:-1]\n",
    "    y_test_ = y_.iloc[-1:]\n",
    "    \n",
    "    comb_nb = CombinedNB(num_feat=['Taxable Income'])\n",
    "    comb_nb.fit(X_train_, y_train_)\n",
    "    comb_nb_preds = comb_nb.predict(X_test_)\n",
    "        \n",
    "    assert (comb_nb.cat_model.category_count_[0][0] == [4., 3.]).all()\n",
    "    assert (comb_nb.cat_model.category_count_[0][1] == [3., 0.]).all()\n",
    "    assert (comb_nb.cat_model.category_count_[1][0] == [1., 4., 2.]).all()\n",
    "    assert (comb_nb.cat_model.category_count_[1][1] == [1., 0., 2.]).all()\n",
    "    assert (comb_nb.num_model.class_count_ == np.array([7., 3.])).all()\n",
    "    assert (comb_nb.num_model.class_prior_ == np.array([0.7, 0.3])).all()\n",
    "    assert (comb_nb.num_model.theta_ == np.array([[110.], [ 90.]])).all()\n",
    "    assert (np.round(comb_nb.num_model.var_) == np.round(np.array([[2550.00000187], [16.66666854]]))).all()\n",
    "    assert comb_nb_preds == 0\n",
    "    \n",
    "    # convert log probabilities to probabilities\n",
    "    feature_probs_0 = np.exp(comb_nb.cat_model.feature_log_prob_[0])\n",
    "    feature_probs_1 = np.exp(comb_nb.cat_model.feature_log_prob_[1])\n",
    "    \n",
    "    assert (np.round(feature_probs_0[0], 2) == np.round(np.array([0.55555556, 0.44444444]), 2)).all()\n",
    "    assert (np.round(feature_probs_0[1], 2) == np.round(np.array([0.8, 0.2]), 2)).all()\n",
    "    assert (np.round(feature_probs_1[0], 2) == np.round(np.array([0.2, 0.5, 0.3]), 2)).all()\n",
    "    assert (np.round(feature_probs_1[1], 2) == np.round(np.array([0.33333333, 0.16666667, 0.5]), 2)).all()\n",
    "    \n",
    "    print(\"All tests passed successfully!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.317670900Z",
     "start_time": "2024-04-29T01:06:45.229035900Z"
    }
   },
   "id": "74872c98f1e6a1da",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed successfully!\n"
     ]
    }
   ],
   "source": [
    "test_combined_nb_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.334624900Z",
     "start_time": "2024-04-29T01:06:45.257009300Z"
    }
   },
   "id": "76a52f0b30900338",
   "execution_count": 85
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training and Evaluating the Combined Naive Bayes Model\n",
    "\n",
    "Since Naive Bayes uses the independence assumption, one-hot encoding features is not a smart idea. We will use label encoding for all categorical features. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "477cae3f83c449"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Naive Bayes Accuracy: 0.7738888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1175\n",
      "           1       0.66      0.72      0.69       625\n",
      "\n",
      "    accuracy                           0.77      1800\n",
      "   macro avg       0.75      0.76      0.76      1800\n",
      "weighted avg       0.78      0.77      0.78      1800\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "comb_nb = CombinedNB(num_feat=['age', 'workinghours'])\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Combined Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.386486700Z",
     "start_time": "2024-04-29T01:06:45.279772500Z"
    }
   },
   "id": "5341fe8a2cb42db9",
   "execution_count": 86
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try a different subset of features for the Combined Naive Bayes model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28ad605f9ca029e1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Naive Bayes Accuracy: 0.7716666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1175\n",
      "           1       0.67      0.67      0.67       625\n",
      "\n",
      "    accuracy                           0.77      1800\n",
      "   macro avg       0.75      0.75      0.75      1800\n",
      "weighted avg       0.77      0.77      0.77      1800\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['age', 'ability to speak english', 'workclass']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "comb_nb = CombinedNB(num_feat=['workinghours'])\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Combined Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.501179400Z",
     "start_time": "2024-04-29T01:06:45.333628800Z"
    }
   },
   "id": "7352ed3187df04f4",
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Naive Bayes Accuracy: 0.7838888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84      1175\n",
      "           1       0.70      0.65      0.68       625\n",
      "\n",
      "    accuracy                           0.78      1800\n",
      "   macro avg       0.76      0.75      0.76      1800\n",
      "weighted avg       0.78      0.78      0.78      1800\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['gave birth this year', 'marital status']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "comb_nb = CombinedNB(num_feat=['age', 'workinghours'])\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Combined Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.585463Z",
     "start_time": "2024-04-29T01:06:45.395462400Z"
    }
   },
   "id": "71cf949d0da904fb",
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Naive Bayes Accuracy: 0.7538888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1175\n",
      "           1       0.66      0.60      0.63       625\n",
      "\n",
      "    accuracy                           0.75      1800\n",
      "   macro avg       0.73      0.72      0.72      1800\n",
      "weighted avg       0.75      0.75      0.75      1800\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['sex', 'gave birth this year', 'marital status']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "comb_nb = CombinedNB(num_feat=['age', 'workinghours'])\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Combined Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.622351100Z",
     "start_time": "2024-04-29T01:06:45.514031100Z"
    }
   },
   "id": "634ebbec242615c4",
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Mixed Naive Bayes Model: library implementation\n",
    "\n",
    "I only later found out this library implementation of Mixed Naive Bayes, although I don't know its internal wokrings. We can use it too to compare the results."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83d4cf95bba046c3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed Naive Bayes Accuracy: 0.7755555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1175\n",
      "           1       0.66      0.72      0.69       625\n",
      "\n",
      "    accuracy                           0.78      1800\n",
      "   macro avg       0.75      0.76      0.76      1800\n",
      "weighted avg       0.78      0.78      0.78      1800\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# the library implementation of MixedNB requires the categorical features to be encoded as integers starting from 0, so we need to encode the education feature separately.\n",
    "le = LabelEncoder()\n",
    "X_train['education'] = le.fit_transform(X_train['education'])\n",
    "X_test['education'] = le.transform(X_test['education'])\n",
    "\n",
    "comb_nb = MixedNB(categorical_features=[1,2,3,4,6,7,8]) # indices of categorical features\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Mixed Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.645289800Z",
     "start_time": "2024-04-29T01:06:45.565515500Z"
    }
   },
   "id": "7db6160745e4247c",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed Naive Bayes Accuracy: 0.7711111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1175\n",
      "           1       0.67      0.67      0.67       625\n",
      "\n",
      "    accuracy                           0.77      1800\n",
      "   macro avg       0.75      0.75      0.75      1800\n",
      "weighted avg       0.77      0.77      0.77      1800\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['age', 'ability to speak english', 'workclass']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# the library implementation of MixedNB requires the categorical features to be encoded as integers starting from 0, so we need to encode the education feature separately.\n",
    "le = LabelEncoder()\n",
    "X_train['education'] = le.fit_transform(X_train['education'])\n",
    "X_test['education'] = le.transform(X_test['education'])\n",
    "comb_nb = MixedNB(categorical_features=[0,1,2,4,5]) # indices of categorical features\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Mixed Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.704155600Z",
     "start_time": "2024-04-29T01:06:45.617364600Z"
    }
   },
   "id": "4c355633bd21466a",
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed Naive Bayes Accuracy: 0.7533333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1175\n",
      "           1       0.66      0.60      0.63       625\n",
      "\n",
      "    accuracy                           0.75      1800\n",
      "   macro avg       0.73      0.72      0.72      1800\n",
      "weighted avg       0.75      0.75      0.75      1800\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['sex', 'gave birth this year', 'marital status']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# the library implementation of MixedNB requires the categorical features to be encoded as integers starting from 0, so we need to encode the education feature separately.\n",
    "le = LabelEncoder()\n",
    "X_train['education'] = le.fit_transform(X_train['education'])\n",
    "X_test['education'] = le.transform(X_test['education'])\n",
    "\n",
    "comb_nb = MixedNB(categorical_features=[1,2,3,5]) # indices of categorical features\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Mixed Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.744049100Z",
     "start_time": "2024-04-29T01:06:45.664262500Z"
    }
   },
   "id": "f95e88b20ee78592",
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed Naive Bayes Accuracy: 0.7844444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84      1175\n",
      "           1       0.70      0.65      0.68       625\n",
      "\n",
      "    accuracy                           0.78      1800\n",
      "   macro avg       0.76      0.75      0.76      1800\n",
      "weighted avg       0.78      0.78      0.78      1800\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['gave birth this year', 'marital status']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# the library implementation of MixedNB requires the categorical features to be encoded as integers starting from 0, so we need to encode the education feature separately.\n",
    "le = LabelEncoder()\n",
    "X_train['education'] = le.fit_transform(X_train['education'])\n",
    "X_test['education'] = le.transform(X_test['education'])\n",
    "\n",
    "comb_nb = MixedNB(categorical_features=[1,2,3,5,6]) # indices of categorical features\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Mixed Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.802960600Z",
     "start_time": "2024-04-29T01:06:45.723104600Z"
    }
   },
   "id": "4dffea56e5c1334f",
   "execution_count": 93
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Categorical Naive Bayes Model\n",
    "\n",
    "Finally, we can try categorizing the numerical features and training a Categorical Naive Bayes model on a dataset that now has only categorical features."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3866426f79e38661"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1175\n",
      "           1       0.67      0.74      0.70       625\n",
      "\n",
      "    accuracy                           0.78      1800\n",
      "   macro avg       0.76      0.77      0.76      1800\n",
      "weighted avg       0.79      0.78      0.78      1800\n",
      "\n",
      "Naive Bayes Accuracy: 0.7811111111111111\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "# we categorize the age and workinghours features, so that all features are categorical\n",
    "X_encoded = X_encoded.drop(columns=['age', 'workinghours'])\n",
    "X_encoded['age'] = pd.cut(X['age'], bins=[0,28,38,49,65,93], labels=['(17-28]', '(28-38]', '(38-49]', '(49-65]', '(65-93]'])\n",
    "X_encoded['workinghours'] = pd.cut(X['workinghours'], bins=[0, 30, 40, 99], labels=['Part-time', 'Full-time', 'Overtime'])\n",
    "\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_cat = CategoricalNB()\n",
    "nb_cat.fit(X_train, y_train)\n",
    "nb_preds = nb_cat.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_preds)\n",
    "\n",
    "print(classification_report(y_test, nb_preds))\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.860064900Z",
     "start_time": "2024-04-29T01:06:45.774966400Z"
    }
   },
   "id": "e2578ad3831e4c15",
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1175\n",
      "           1       0.68      0.68      0.68       625\n",
      "\n",
      "    accuracy                           0.78      1800\n",
      "   macro avg       0.76      0.76      0.76      1800\n",
      "weighted avg       0.78      0.78      0.78      1800\n",
      "\n",
      "Naive Bayes Accuracy: 0.7788888888888889\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['age', 'ability to speak english', 'workclass']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# we categorize the age and workinghours features, so that all features are categorical\n",
    "X_encoded = X_encoded.drop(columns=['workinghours'])\n",
    "X_encoded['workinghours'] = pd.cut(X['workinghours'], bins=[0, 30, 40, 99], labels=['Part-time', 'Full-time', 'Overtime'])\n",
    "\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_cat = CategoricalNB()\n",
    "nb_cat.fit(X_train, y_train)\n",
    "nb_preds = nb_cat.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_preds)\n",
    "\n",
    "print(classification_report(y_test, nb_preds))\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.922449800Z",
     "start_time": "2024-04-29T01:06:45.853083100Z"
    }
   },
   "id": "c849dd578a43771f",
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1175\n",
      "           1       0.67      0.63      0.65       625\n",
      "\n",
      "    accuracy                           0.76      1800\n",
      "   macro avg       0.74      0.73      0.73      1800\n",
      "weighted avg       0.76      0.76      0.76      1800\n",
      "\n",
      "Naive Bayes Accuracy: 0.7622222222222222\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['sex', 'gave birth this year', 'marital status']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# we categorize the age and workinghours features, so that all features are categorical\n",
    "X_encoded = X_encoded.drop(columns=['age', 'workinghours'])\n",
    "X_encoded['age'] = pd.cut(X['age'], bins=[0,28,38,49,65,93], labels=['(17-28]', '(28-38]', '(38-49]', '(49-65]', '(65-93]'])\n",
    "X_encoded['workinghours'] = pd.cut(X['workinghours'], bins=[0, 30, 40, 99], labels=['Part-time', 'Full-time', 'Overtime'])\n",
    "\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_cat = CategoricalNB()\n",
    "nb_cat.fit(X_train, y_train)\n",
    "nb_preds = nb_cat.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_preds)\n",
    "\n",
    "print(classification_report(y_test, nb_preds))\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:45.972403900Z",
     "start_time": "2024-04-29T01:06:45.922449800Z"
    }
   },
   "id": "422f740c40213d15",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1175\n",
      "           1       0.68      0.66      0.67       625\n",
      "\n",
      "    accuracy                           0.78      1800\n",
      "   macro avg       0.75      0.75      0.75      1800\n",
      "weighted avg       0.77      0.78      0.77      1800\n",
      "\n",
      "Naive Bayes Accuracy: 0.7755555555555556\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['gave birth this year', 'marital status']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# we categorize the age and workinghours features, so that all features are categorical\n",
    "X_encoded = X_encoded.drop(columns=['age', 'workinghours'])\n",
    "X_encoded['age'] = pd.cut(X['age'], bins=[0,28,38,49,65,93], labels=['(17-28]', '(28-38]', '(38-49]', '(49-65]', '(65-93]'])\n",
    "X_encoded['workinghours'] = pd.cut(X['workinghours'], bins=[0, 30, 40, 99], labels=['Part-time', 'Full-time', 'Overtime'])\n",
    "\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_cat = CategoricalNB()\n",
    "nb_cat.fit(X_train, y_train)\n",
    "nb_preds = nb_cat.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_preds)\n",
    "\n",
    "print(classification_report(y_test, nb_preds))\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:46.022081100Z",
     "start_time": "2024-04-29T01:06:45.966420400Z"
    }
   },
   "id": "ada0d2f3626614e5",
   "execution_count": 97
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Naive Bayes models do not have many hyperparameters to tune. We won't do any hyperparameter tuning for any models here."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9423e3ffd4469d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving the Model(s)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6ce32c604f62593"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# save model\n",
    "save_model(nb_model, '../output/saved_models/naive_bayes_model.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T01:06:46.024074800Z",
     "start_time": "2024-04-29T01:06:46.015100Z"
    }
   },
   "id": "eac15450e6ee09ea",
   "execution_count": 98
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
