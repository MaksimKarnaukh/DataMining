{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-21T21:49:39.688216100Z",
     "start_time": "2024-04-21T21:49:39.630914500Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from helper.helper_functions import load_dataset, save_model, get_features_and_target, encode_all_features\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the cleaned dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ced45577f2a46d2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = load_dataset('../data/assignment2_income_cleaned.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T21:49:41.584026Z",
     "start_time": "2024-04-21T21:49:39.666274500Z"
    }
   },
   "id": "573b15a0c08becd2",
   "execution_count": 164
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Splitting the data into features (X) and target (y)\n",
    "X, y = get_features_and_target(data, 'income')\n",
    "columns_to_exclude = ['sex', 'ability to speak english', 'gave birth this year']\n",
    "# Encoding the features and target, and excluding some columns\n",
    "X_encoded, y_encoded = encode_all_features(X, y, [])\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T21:49:41.628403300Z",
     "start_time": "2024-04-21T21:49:41.586026400Z"
    }
   },
   "id": "6aef9cfa1cf6ddd3",
   "execution_count": 165
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfc5f29026270e84"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.78      1175\n",
      "           1       0.58      0.71      0.64       625\n",
      "\n",
      "    accuracy                           0.72      1800\n",
      "   macro avg       0.70      0.72      0.71      1800\n",
      "weighted avg       0.74      0.72      0.73      1800\n",
      "\n",
      "Naive Bayes Accuracy: 0.7227777777777777\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes model (Gaussian)\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "nb_preds = nb_model.predict(X_test)\n",
    "# Accuracy evaluation\n",
    "nb_accuracy = accuracy_score(y_test, nb_preds)\n",
    "\n",
    "print(classification_report(y_test, nb_preds))\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T21:49:41.668547200Z",
     "start_time": "2024-04-21T21:49:41.630399800Z"
    }
   },
   "id": "7c4fcfd7603fcff1",
   "execution_count": 166
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "\n",
    "class CombinedNB:\n",
    "    \"\"\"\n",
    "    Combined Naive Bayes model for mixed data types (categorical and numerical)\n",
    "    This looks a bit like a sklearn classifier class, but it's not (it doesn't inherit from anything). It's just a simple class that implements the fit and predict methods only for two combined Naive Bayes models.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_feat: List[str], cat_model: CategoricalNB = CategoricalNB(), num_model: GaussianNB = GaussianNB()):\n",
    "        self.cat_model: CategoricalNB = cat_model\n",
    "        self.num_model: GaussianNB = num_model\n",
    "        self.num_feat: List[str] = num_feat # numerical features\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit the combined model to the training data. We fit the categorical model to the categorical features and the numerical model to the numerical features.\n",
    "        :param X_train: training dataset with mixed features\n",
    "        :param y_train: training dataset with target variable\n",
    "        :return: \n",
    "        \"\"\"\n",
    "        # Splitting data into categorical and numerical features\n",
    "        X_train_cat = X_train.drop(columns=self.num_feat)\n",
    "        X_train_num = X_train[self.num_feat]\n",
    "\n",
    "        self.cat_model.fit(X_train_cat, y_train)\n",
    "        self.num_model.fit(X_train_num, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict the target variable for the test data.\n",
    "        We use the formula: \n",
    "        P(Class | C1, ..., Cn, N1, ..., Nm) ~= Mult{1, n}(P(Ci | Class)) * Mult{1, m}(P(Nj | Class)) * P(Class)\n",
    "        where Ci are the categorical features, Nj are the numerical features, and Class is the target variable. \n",
    "        Concerning the scores, we get the following:\n",
    "        Cat * Num * Prior = (Score_cat * Score_num) / Prior\n",
    "        :param X_test: test dataset with mixed features\n",
    "        :return: predicted target variable\n",
    "        \"\"\"\n",
    "        cat_probs = self.cat_model.predict_proba(X_test.drop(columns=self.num_feat))\n",
    "        num_probs = self.num_model.predict_proba(X_test[self.num_feat])\n",
    "        combined_probs = (cat_probs * num_probs) / self.num_model.class_prior_\n",
    "        combined_probs /= combined_probs.sum(axis=1, keepdims=True)\n",
    "        return np.argmax(combined_probs, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T21:49:41.698466400Z",
     "start_time": "2024-04-21T21:49:41.662562300Z"
    }
   },
   "id": "33c11ade77e2c784",
   "execution_count": 167
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test_combined_nb_model():\n",
    "    data_ = {\n",
    "    'Refund': ['Yes', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No'],\n",
    "    'Marital Status': ['Single', 'Married', 'Single', 'Married', 'Divorced', 'Married', 'Divorced', 'Single', 'Married', 'Single', 'Divorced'],\n",
    "    'Taxable Income': [125, 100, 70, 120, 95, 60, 220, 85, 75, 90, 120],\n",
    "    'Evade': ['No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No']\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data_)\n",
    "    \n",
    "    # Encoding the features and target\n",
    "    le_ = LabelEncoder()\n",
    "    for col in df.columns:\n",
    "        if col not in ['Taxable Income']:\n",
    "            enc = le_.fit_transform(df[col])\n",
    "            df[col] = enc\n",
    "            # print encoding mapping\n",
    "            print(f\"Mapping for {col}:\")\n",
    "            for original, encoded in zip(le_.classes_, range(len(le_.classes_))):\n",
    "                print(f\"{original} -> {encoded}\")\n",
    "    \n",
    "    # Separate features (X) and target variable (y)\n",
    "    X_ = df.iloc[:, :-1]  # All columns except the last one\n",
    "    y_ = df.iloc[:, -1]   # Last column (Evade)\n",
    "    \n",
    "    # Splitting data into training and test sets\n",
    "    X_train_ = X_.iloc[:-1]  # All rows except the last one\n",
    "    X_test_ = X_.iloc[-1:]   # Last row\n",
    "    y_train_ = y_.iloc[:-1]  # All rows except the last one\n",
    "    y_test_ = y_.iloc[-1:]   # Last row\n",
    "    \n",
    "    comb_nb = CombinedNB(num_feat=['Taxable Income'])\n",
    "    comb_nb.fit(X_train_, y_train_)\n",
    "    comb_nb_preds = comb_nb.predict(X_test_)\n",
    "    \n",
    "    assert (comb_nb.cat_model.category_count_[0][0] == [4., 3.]).all()\n",
    "    assert (comb_nb.cat_model.category_count_[0][1] == [3., 0.]).all()\n",
    "    assert (comb_nb.cat_model.category_count_[1][0] == [1., 4., 2.]).all()\n",
    "    assert (comb_nb.cat_model.category_count_[1][1] == [1., 0., 2.]).all()\n",
    "    assert (comb_nb.num_model.class_count_ == np.array([7., 3.])).all()\n",
    "    assert (comb_nb.num_model.class_prior_ == np.array([0.7, 0.3])).all()\n",
    "    assert (comb_nb.num_model.theta_ == np.array([[110.], [ 90.]])).all()\n",
    "    assert (np.round(comb_nb.num_model.var_) == np.round(np.array([[2550.00000187], [16.66666854]]))).all()\n",
    "    assert comb_nb_preds == 0\n",
    "    \n",
    "    # convert log probabilities to probabilities\n",
    "    feature_probs_0 = np.exp(comb_nb.cat_model.feature_log_prob_[0])\n",
    "    feature_probs_1 = np.exp(comb_nb.cat_model.feature_log_prob_[1])\n",
    "    \n",
    "    print(feature_probs_0)\n",
    "    print(feature_probs_1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T21:49:41.749146100Z",
     "start_time": "2024-04-21T21:49:41.673533700Z"
    }
   },
   "id": "74872c98f1e6a1da",
   "execution_count": 168
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping for Refund:\n",
      "No -> 0\n",
      "Yes -> 1\n",
      "Mapping for Marital Status:\n",
      "Divorced -> 0\n",
      "Married -> 1\n",
      "Single -> 2\n",
      "Mapping for Evade:\n",
      "No -> 0\n",
      "Yes -> 1\n",
      "[[0.55555556 0.44444444]\n",
      " [0.8        0.2       ]]\n",
      "[[0.2        0.5        0.3       ]\n",
      " [0.33333333 0.16666667 0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "test_combined_nb_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T21:49:41.770090900Z",
     "start_time": "2024-04-21T21:49:41.751141600Z"
    }
   },
   "id": "76a52f0b30900338",
   "execution_count": 169
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Naive Bayes Accuracy: 0.7738888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1175\n",
      "           1       0.66      0.72      0.69       625\n",
      "\n",
      "    accuracy                           0.77      1800\n",
      "   macro avg       0.75      0.76      0.76      1800\n",
      "weighted avg       0.78      0.77      0.78      1800\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "comb_nb = CombinedNB(num_feat=['age', 'workinghours'])\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Combined Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T21:49:41.835064600Z",
     "start_time": "2024-04-21T21:49:41.771087800Z"
    }
   },
   "id": "5341fe8a2cb42db9",
   "execution_count": 170
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1175\n",
      "           1       0.69      0.67      0.68       625\n",
      "\n",
      "    accuracy                           0.78      1800\n",
      "   macro avg       0.76      0.76      0.76      1800\n",
      "weighted avg       0.78      0.78      0.78      1800\n",
      "\n",
      "Naive Bayes Accuracy: 0.7811111111111111\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "X_encoded = X_encoded.drop(columns=['age', 'workinghours'])\n",
    "# X_encoded['age'] = pd.cut(X['age'], bins=[0,28,38,49,65,93], labels=['(17-28]', '(28-38]', '(38-49]', '(49-65]', '(65-93]'])\n",
    "X_encoded['workinghours'] = pd.cut(X['workinghours'], bins=[0, 30, 40, 99], labels=['Part-time', 'Full-time', 'Overtime'])\n",
    "\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_cat = CategoricalNB()\n",
    "nb_cat.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "nb_preds = nb_cat.predict(X_test)\n",
    "# Accuracy evaluation\n",
    "nb_accuracy = accuracy_score(y_test, nb_preds)\n",
    "\n",
    "print(classification_report(y_test, nb_preds))\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T21:49:42.034707800Z",
     "start_time": "2024-04-21T21:49:41.834066800Z"
    }
   },
   "id": "e2578ad3831e4c15",
   "execution_count": 171
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# save model\n",
    "save_model(nb_model, '../output/saved_models/naive_bayes_model.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T21:49:42.083911500Z",
     "start_time": "2024-04-21T21:49:42.031737100Z"
    }
   },
   "id": "eac15450e6ee09ea",
   "execution_count": 172
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
