{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:04.567952700Z",
     "start_time": "2024-05-01T00:48:04.038807300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'ot': ot_distance will be unavailable. To install, run:\n",
      "pip install 'aif360[OptimalTransport]'\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from helper.helper_functions import load_dataset, save_model, get_features_and_target, encode_all_features, get_train_test_with_excluded_columns\n",
    "from helper.fairness_functions import print_male_female_metrics, get_male_female_data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from mixed_naive_bayes import MixedNB # https://pypi.org/project/mixed-naive-bayes/#api-documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the cleaned dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ced45577f2a46d2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = load_dataset('../data/assignment2_income_cleaned.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:06.642878700Z",
     "start_time": "2024-05-01T00:48:04.559973600Z"
    }
   },
   "id": "573b15a0c08becd2",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Engineering (encoding) & Train-Test Split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7592687113789b2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Splitting the data into features (X) and target (y)\n",
    "X, y = get_features_and_target(data, 'income')\n",
    "X_male, X_female = get_male_female_data(X, False)\n",
    "# Encoding the features and target, and excluding some columns\n",
    "X_encoded, y_encoded = encode_all_features(X, y, [])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:06.684818800Z",
     "start_time": "2024-05-01T00:48:06.642878700Z"
    }
   },
   "id": "6aef9cfa1cf6ddd3",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      age  education  workinghours  ability to speak english  \\\n6317   22         16            36                         0   \n740    61         22            40                         1   \n3781   48         16            40                         0   \n7850   62         18            65                         0   \n2963   53         19            44                         0   \n...   ...        ...           ...                       ...   \n5734   22         19            25                         0   \n5191   24         16            28                         0   \n5390   35         16            40                         0   \n860    23         20            40                         0   \n7270   70         19            40                         0   \n\n      marital status_Divorced  marital status_Husband  \\\n6317                        0                       1   \n740                         1                       0   \n3781                        1                       0   \n7850                        0                       1   \n2963                        1                       0   \n...                       ...                     ...   \n5734                        0                       0   \n5191                        0                       0   \n5390                        0                       0   \n860                         0                       0   \n7270                        1                       0   \n\n      marital status_Never married  marital status_Separated  \\\n6317                             0                         0   \n740                              0                         0   \n3781                             0                         0   \n7850                             0                         0   \n2963                             0                         0   \n...                            ...                       ...   \n5734                             1                         0   \n5191                             1                         0   \n5390                             1                         0   \n860                              1                         0   \n7270                             0                         0   \n\n      marital status_Widowed  marital status_Wife  ...  \\\n6317                       0                    0  ...   \n740                        0                    0  ...   \n3781                       0                    0  ...   \n7850                       0                    0  ...   \n2963                       0                    0  ...   \n...                      ...                  ...  ...   \n5734                       0                    0  ...   \n5191                       0                    0  ...   \n5390                       0                    0  ...   \n860                        0                    0  ...   \n7270                       0                    0  ...   \n\n      occupation_Service/Hospitality  occupation_Transport  \\\n6317                               0                     0   \n740                                0                     0   \n3781                               0                     0   \n7850                               0                     0   \n2963                               0                     0   \n...                              ...                   ...   \n5734                               1                     0   \n5191                               0                     0   \n5390                               0                     0   \n860                                1                     0   \n7270                               0                     0   \n\n      gave birth this year_No  gave birth this year_Yes  \\\n6317                        1                         0   \n740                         1                         0   \n3781                        1                         0   \n7850                        1                         0   \n2963                        1                         0   \n...                       ...                       ...   \n5734                        1                         0   \n5191                        1                         0   \n5390                        1                         0   \n860                         1                         0   \n7270                        1                         0   \n\n      workclass_governmental  workclass_no paid work  workclass_private  \\\n6317                       0                       0                  1   \n740                        0                       0                  0   \n3781                       0                       0                  1   \n7850                       0                       0                  1   \n2963                       1                       0                  0   \n...                      ...                     ...                ...   \n5734                       0                       0                  1   \n5191                       0                       0                  1   \n5390                       0                       0                  1   \n860                        0                       0                  1   \n7270                       0                       1                  0   \n\n      workclass_self employed  sex_Female  sex_Male  \n6317                        0           0         1  \n740                         1           0         1  \n3781                        0           1         0  \n7850                        0           0         1  \n2963                        0           1         0  \n...                       ...         ...       ...  \n5734                        0           1         0  \n5191                        0           1         0  \n5390                        0           0         1  \n860                         0           0         1  \n7270                        0           1         0  \n\n[7200 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>education</th>\n      <th>workinghours</th>\n      <th>ability to speak english</th>\n      <th>marital status_Divorced</th>\n      <th>marital status_Husband</th>\n      <th>marital status_Never married</th>\n      <th>marital status_Separated</th>\n      <th>marital status_Widowed</th>\n      <th>marital status_Wife</th>\n      <th>...</th>\n      <th>occupation_Service/Hospitality</th>\n      <th>occupation_Transport</th>\n      <th>gave birth this year_No</th>\n      <th>gave birth this year_Yes</th>\n      <th>workclass_governmental</th>\n      <th>workclass_no paid work</th>\n      <th>workclass_private</th>\n      <th>workclass_self employed</th>\n      <th>sex_Female</th>\n      <th>sex_Male</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6317</th>\n      <td>22</td>\n      <td>16</td>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>740</th>\n      <td>61</td>\n      <td>22</td>\n      <td>40</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3781</th>\n      <td>48</td>\n      <td>16</td>\n      <td>40</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7850</th>\n      <td>62</td>\n      <td>18</td>\n      <td>65</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2963</th>\n      <td>53</td>\n      <td>19</td>\n      <td>44</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5734</th>\n      <td>22</td>\n      <td>19</td>\n      <td>25</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5191</th>\n      <td>24</td>\n      <td>16</td>\n      <td>28</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5390</th>\n      <td>35</td>\n      <td>16</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>23</td>\n      <td>20</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7270</th>\n      <td>70</td>\n      <td>19</td>\n      <td>40</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7200 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:06.700913300Z",
     "start_time": "2024-05-01T00:48:06.670856300Z"
    }
   },
   "id": "495ea34f27ff398f",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model\n",
    "\n",
    "Here, we quickly train and evaluate a Gaussian Naive Bayes model for demonstration."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfc5f29026270e84"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.78      1175\n",
      "           1       0.58      0.71      0.64       625\n",
      "\n",
      "    accuracy                           0.72      1800\n",
      "   macro avg       0.70      0.72      0.71      1800\n",
      "weighted avg       0.74      0.72      0.73      1800\n",
      "\n",
      "Naive Bayes Accuracy: 0.7227777777777777\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes model (Gaussian)\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_preds = nb_model.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_preds)\n",
    "\n",
    "print(classification_report(y_test, nb_preds))\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:06.758442700Z",
     "start_time": "2024-05-01T00:48:06.694929600Z"
    }
   },
   "id": "7c4fcfd7603fcff1",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combined Naive Bayes Model: Custom Implementation\n",
    "\n",
    "Below we implement and train a Combined Naive Bayes model for mixed data types (categorical and numerical)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "595fb7cd421a19ff"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CombinedNB:\n",
    "    \"\"\"\n",
    "    Combined Naive Bayes model for mixed data types (categorical and numerical)\n",
    "    This looks a bit like a sklearn classifier class, but it's not (it doesn't inherit from anything). It's just a simple class that implements the fit and predict methods only, for two combined Naive Bayes models.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_feat: List[str], cat_model: CategoricalNB = CategoricalNB(), num_model: GaussianNB = GaussianNB()):\n",
    "        self.cat_model: CategoricalNB = cat_model\n",
    "        self.num_model: GaussianNB = num_model\n",
    "        self.num_feat: List[str] = num_feat # numerical features\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit the combined model to the training data. We fit the categorical model to the categorical features and the numerical model to the numerical features.\n",
    "        :param X_train: training dataset with mixed features\n",
    "        :param y_train: training dataset with target variable\n",
    "        :return: \n",
    "        \"\"\"\n",
    "        # Splitting data into categorical and numerical features\n",
    "        X_train_cat = X_train.drop(columns=self.num_feat)\n",
    "        X_train_num = X_train[self.num_feat]\n",
    "\n",
    "        self.cat_model.fit(X_train_cat, y_train)\n",
    "        self.num_model.fit(X_train_num, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict the target variable for the test data.\n",
    "        \n",
    "        We use the formula: \n",
    "        P(Class | C1, ..., Cn, N1, ..., Nm) ~= Mult{1, n}(P(Ci | Class)) * Mult{1, m}(P(Nj | Class)) * P(Class)\n",
    "        \n",
    "        where Ci are the categorical features, Nj are the numerical features, and Class is the target variable. \n",
    "        Concerning the scores, we get the following:\n",
    "        Cat * Num * Prior = (Score_cat * Score_num) / Prior\n",
    "\n",
    "        Note: CategoricalNB uses Laplace smoothing by default.\n",
    "        \n",
    "        :param X_test: test dataset with mixed features\n",
    "        :return: predicted target variable\n",
    "        \"\"\"\n",
    "        cat_probs = self.cat_model.predict_proba(X_test.drop(columns=self.num_feat))\n",
    "        num_probs = self.num_model.predict_proba(X_test[self.num_feat])\n",
    "        combined_probs = (cat_probs * num_probs) / self.num_model.class_prior_\n",
    "        # combined_probs /= combined_probs.sum(axis=1, keepdims=True) # normalize the probabilities\n",
    "        return np.argmax(combined_probs, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:06.759439900Z",
     "start_time": "2024-05-01T00:48:06.725381800Z"
    }
   },
   "id": "33c11ade77e2c784",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Testing the Combined Naive Bayes Model\n",
    "\n",
    "Below is a small test function for the Combined Naive Bayes model. We will test the model on a small dataset to check if it's generally working correctly. The test is based on the example from the lecture slides by Toon Calders."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfe2fdcca4589a97"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test_combined_nb_model(print_mapping=False):\n",
    "    data_ = {\n",
    "    'Refund': ['Yes', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No'],\n",
    "    'Marital Status': ['Single', 'Married', 'Single', 'Married', 'Divorced', 'Married', 'Divorced', 'Single', 'Married', 'Single', 'Divorced'],\n",
    "    'Taxable Income': [125, 100, 70, 120, 95, 60, 220, 85, 75, 90, 120],\n",
    "    'Evade': ['No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No']\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data_)\n",
    "    \n",
    "    # Encoding features and target\n",
    "    le_ = LabelEncoder()\n",
    "    for col in df.columns:\n",
    "        if col not in ['Taxable Income']:\n",
    "            enc = le_.fit_transform(df[col])\n",
    "            df[col] = enc\n",
    "            # print encoding mapping\n",
    "            if print_mapping:\n",
    "                print(f\"Mapping for {col}:\")\n",
    "                for original, encoded in zip(le_.classes_, range(len(le_.classes_))):\n",
    "                    print(f\"{original} -> {encoded}\")\n",
    "    \n",
    "    # Separate features (X) and target variable (y)\n",
    "    X_ = df.iloc[:, :-1]\n",
    "    y_ = df.iloc[:, -1]\n",
    "    \n",
    "    # Splitting data into training and test sets\n",
    "    X_train_ = X_.iloc[:-1]\n",
    "    X_test_ = X_.iloc[-1:]\n",
    "    y_train_ = y_.iloc[:-1]\n",
    "    y_test_ = y_.iloc[-1:]\n",
    "    \n",
    "    comb_nb = CombinedNB(num_feat=['Taxable Income'])\n",
    "    comb_nb.fit(X_train_, y_train_)\n",
    "    comb_nb_preds = comb_nb.predict(X_test_)\n",
    "        \n",
    "    assert (comb_nb.cat_model.category_count_[0][0] == [4., 3.]).all()\n",
    "    assert (comb_nb.cat_model.category_count_[0][1] == [3., 0.]).all()\n",
    "    assert (comb_nb.cat_model.category_count_[1][0] == [1., 4., 2.]).all()\n",
    "    assert (comb_nb.cat_model.category_count_[1][1] == [1., 0., 2.]).all()\n",
    "    assert (comb_nb.num_model.class_count_ == np.array([7., 3.])).all()\n",
    "    assert (comb_nb.num_model.class_prior_ == np.array([0.7, 0.3])).all()\n",
    "    assert (comb_nb.num_model.theta_ == np.array([[110.], [ 90.]])).all()\n",
    "    assert (np.round(comb_nb.num_model.var_) == np.round(np.array([[2550.00000187], [16.66666854]]))).all()\n",
    "    assert comb_nb_preds == 0\n",
    "    \n",
    "    # convert log probabilities to probabilities\n",
    "    feature_probs_0 = np.exp(comb_nb.cat_model.feature_log_prob_[0])\n",
    "    feature_probs_1 = np.exp(comb_nb.cat_model.feature_log_prob_[1])\n",
    "    \n",
    "    assert (np.round(feature_probs_0[0], 2) == np.round(np.array([0.55555556, 0.44444444]), 2)).all()\n",
    "    assert (np.round(feature_probs_0[1], 2) == np.round(np.array([0.8, 0.2]), 2)).all()\n",
    "    assert (np.round(feature_probs_1[0], 2) == np.round(np.array([0.2, 0.5, 0.3]), 2)).all()\n",
    "    assert (np.round(feature_probs_1[1], 2) == np.round(np.array([0.33333333, 0.16666667, 0.5]), 2)).all()\n",
    "    \n",
    "    print(\"All tests passed successfully!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:06.870740300Z",
     "start_time": "2024-05-01T00:48:06.733802700Z"
    }
   },
   "id": "74872c98f1e6a1da",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed successfully!\n"
     ]
    }
   ],
   "source": [
    "test_combined_nb_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:06.874730200Z",
     "start_time": "2024-05-01T00:48:06.753457200Z"
    }
   },
   "id": "76a52f0b30900338",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training and Evaluating the Combined Naive Bayes Model\n",
    "\n",
    "Since Naive Bayes uses the independence assumption, one-hot encoding features is not a smart idea. We will use label encoding for all categorical features. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "477cae3f83c449"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Naive Bayes Accuracy: 0.7738888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1175\n",
      "           1       0.66      0.72      0.69       625\n",
      "\n",
      "    accuracy                           0.77      1800\n",
      "   macro avg       0.75      0.76      0.76      1800\n",
      "weighted avg       0.78      0.77      0.78      1800\n",
      "\n",
      "Fairness Metrics:\n",
      "Male FPR: 0.28067700987306066\n",
      "Male TPR: 0.8036072144288577\n",
      "Female FPR: 0.06437768240343347\n",
      "Female TPR: 0.36507936507936506\n",
      "\n",
      "Disparate Impact (DI): 0.258\n",
      "Discrimination Score (DS): -0.368\n",
      "Equal Opportunity Difference (EO): 0.439\n",
      "Equalized Odds (EOdds): 0.216\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "comb_nb = CombinedNB(num_feat=['age', 'workinghours'])\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Combined Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))\n",
    "\n",
    "print_male_female_metrics(comb_nb, X, X_male, X_female, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:06.883706200Z",
     "start_time": "2024-05-01T00:48:06.770789300Z"
    }
   },
   "id": "5341fe8a2cb42db9",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "We try a different subset of features for the Combined Naive Bayes model. We exclude 'age', 'ability to speak english', and 'workclass' features."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28ad605f9ca029e1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Naive Bayes Accuracy: 0.7716666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1175\n",
      "           1       0.67      0.67      0.67       625\n",
      "\n",
      "    accuracy                           0.77      1800\n",
      "   macro avg       0.75      0.75      0.75      1800\n",
      "weighted avg       0.77      0.77      0.77      1800\n",
      "\n",
      "Fairness Metrics:\n",
      "Male FPR: 0.2623413258110014\n",
      "Male TPR: 0.7735470941883767\n",
      "Female FPR: 0.03862660944206009\n",
      "Female TPR: 0.25396825396825395\n",
      "\n",
      "Disparate Impact (DI): 0.178\n",
      "Discrimination Score (DS): -0.389\n",
      "Equal Opportunity Difference (EO): 0.520\n",
      "Equalized Odds (EOdds): 0.224\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['age', 'ability to speak english', 'workclass']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "comb_nb = CombinedNB(num_feat=['workinghours'])\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Combined Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))\n",
    "\n",
    "print_male_female_metrics(comb_nb, X, X_male, X_female, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:06.951682700Z",
     "start_time": "2024-05-01T00:48:06.857775700Z"
    }
   },
   "id": "7352ed3187df04f4",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "We try a different subset of features for the Combined Naive Bayes model. We exclude 'gave birth this year' and 'marital status', two features correlated with 'sex'."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18d7945b7c014caa"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Naive Bayes Accuracy: 0.7838888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84      1175\n",
      "           1       0.70      0.65      0.68       625\n",
      "\n",
      "    accuracy                           0.78      1800\n",
      "   macro avg       0.76      0.75      0.76      1800\n",
      "weighted avg       0.78      0.78      0.78      1800\n",
      "\n",
      "Fairness Metrics:\n",
      "Male FPR: 0.1622002820874471\n",
      "Male TPR: 0.687374749498998\n",
      "Female FPR: 0.12017167381974249\n",
      "Female TPR: 0.5079365079365079\n",
      "\n",
      "Disparate Impact (DI): 0.535\n",
      "Discrimination Score (DS): -0.176\n",
      "Equal Opportunity Difference (EO): 0.179\n",
      "Equalized Odds (EOdds): 0.042\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['gave birth this year', 'marital status']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "comb_nb = CombinedNB(num_feat=['age', 'workinghours'])\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Combined Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))\n",
    "print_male_female_metrics(comb_nb, X, X_male, X_female, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:07.034826500Z",
     "start_time": "2024-05-01T00:48:06.939714300Z"
    }
   },
   "id": "71cf949d0da904fb",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "We try a different subset of features for the Combined Naive Bayes model. We exclude all the sex-related features."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c50223ae75f62295"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Naive Bayes Accuracy: 0.7538888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1175\n",
      "           1       0.66      0.60      0.63       625\n",
      "\n",
      "    accuracy                           0.75      1800\n",
      "   macro avg       0.73      0.72      0.72      1800\n",
      "weighted avg       0.75      0.75      0.75      1800\n",
      "Fairness Metrics:\n",
      "Male FPR: 0.14104372355430184\n",
      "Male TPR: 0.5991983967935872\n",
      "Female FPR: 0.19742489270386265\n",
      "Female TPR: 0.5952380952380952\n",
      "\n",
      "Disparate Impact (DI): 0.854\n",
      "Discrimination Score (DS): -0.048\n",
      "Equal Opportunity Difference (EO): 0.004\n",
      "Equalized Odds (EOdds): -0.056\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['sex', 'gave birth this year', 'marital status']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "comb_nb = CombinedNB(num_feat=['age', 'workinghours'])\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Combined Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))\n",
    "\n",
    "print_male_female_metrics(comb_nb, X, X_male, X_female, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:07.145629800Z",
     "start_time": "2024-05-01T00:48:07.027844900Z"
    }
   },
   "id": "634ebbec242615c4",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Mixed Naive Bayes Model: library implementation\n",
    "\n",
    "I only later found out this library implementation of Mixed Naive Bayes, although I don't know its internal wokrings. We can use it too to compare the results.\n",
    "\n",
    "We use the same column exclusion steps as before."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83d4cf95bba046c3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed Naive Bayes Accuracy: 0.7755555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1175\n",
      "           1       0.66      0.72      0.69       625\n",
      "\n",
      "    accuracy                           0.78      1800\n",
      "   macro avg       0.75      0.76      0.76      1800\n",
      "weighted avg       0.78      0.78      0.78      1800\n",
      "\n",
      "Fairness Metrics:\n",
      "Male FPR: 0.27926657263751764\n",
      "Male TPR: 0.8056112224448898\n",
      "Female FPR: 0.06437768240343347\n",
      "Female TPR: 0.373015873015873\n",
      "\n",
      "Disparate Impact (DI): 0.262\n",
      "Discrimination Score (DS): -0.367\n",
      "Equal Opportunity Difference (EO): 0.433\n",
      "Equalized Odds (EOdds): 0.215\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# the library implementation of MixedNB requires the categorical features to be encoded as integers starting from 0, so we need to encode the education feature separately.\n",
    "le = LabelEncoder()\n",
    "X_train['education'] = le.fit_transform(X_train['education'])\n",
    "X_test['education'] = le.transform(X_test['education'])\n",
    "\n",
    "comb_nb = MixedNB(categorical_features=[1,2,3,4,6,7,8]) # indices of categorical features\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Mixed Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))\n",
    "\n",
    "print_male_female_metrics(comb_nb, X, X_male, X_female, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:07.229402400Z",
     "start_time": "2024-05-01T00:48:07.126681Z"
    }
   },
   "id": "7db6160745e4247c",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed Naive Bayes Accuracy: 0.7711111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1175\n",
      "           1       0.67      0.67      0.67       625\n",
      "\n",
      "    accuracy                           0.77      1800\n",
      "   macro avg       0.75      0.75      0.75      1800\n",
      "weighted avg       0.77      0.77      0.77      1800\n",
      "\n",
      "Fairness Metrics:\n",
      "Male FPR: 0.2623413258110014\n",
      "Male TPR: 0.7715430861723447\n",
      "Female FPR: 0.03862660944206009\n",
      "Female TPR: 0.25396825396825395\n",
      "\n",
      "Disparate Impact (DI): 0.179\n",
      "Discrimination Score (DS): -0.388\n",
      "Equal Opportunity Difference (EO): 0.518\n",
      "Equalized Odds (EOdds): 0.224\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['age', 'ability to speak english', 'workclass']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# the library implementation of MixedNB requires the categorical features to be encoded as integers starting from 0, so we need to encode the education feature separately.\n",
    "le = LabelEncoder()\n",
    "X_train['education'] = le.fit_transform(X_train['education'])\n",
    "X_test['education'] = le.transform(X_test['education'])\n",
    "comb_nb = MixedNB(categorical_features=[0,1,2,4,5]) # indices of categorical features\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Mixed Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))\n",
    "\n",
    "print_male_female_metrics(comb_nb, X, X_male, X_female, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:07.309081200Z",
     "start_time": "2024-05-01T00:48:07.222420900Z"
    }
   },
   "id": "4c355633bd21466a",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed Naive Bayes Accuracy: 0.7533333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1175\n",
      "           1       0.66      0.60      0.63       625\n",
      "\n",
      "    accuracy                           0.75      1800\n",
      "   macro avg       0.73      0.72      0.72      1800\n",
      "weighted avg       0.75      0.75      0.75      1800\n",
      "\n",
      "Fairness Metrics:\n",
      "Male FPR: 0.14104372355430184\n",
      "Male TPR: 0.5971943887775552\n",
      "Female FPR: 0.19742489270386265\n",
      "Female TPR: 0.5952380952380952\n",
      "\n",
      "Disparate Impact (DI): 0.856\n",
      "Discrimination Score (DS): -0.047\n",
      "Equal Opportunity Difference (EO): 0.002\n",
      "Equalized Odds (EOdds): -0.056\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['sex', 'gave birth this year', 'marital status']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# the library implementation of MixedNB requires the categorical features to be encoded as integers starting from 0, so we need to encode the education feature separately.\n",
    "le = LabelEncoder()\n",
    "X_train['education'] = le.fit_transform(X_train['education'])\n",
    "X_test['education'] = le.transform(X_test['education'])\n",
    "\n",
    "comb_nb = MixedNB(categorical_features=[1,2,3,5]) # indices of categorical features\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Mixed Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))\n",
    "\n",
    "print_male_female_metrics(comb_nb, X, X_male, X_female, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:07.392821100Z",
     "start_time": "2024-05-01T00:48:07.307085500Z"
    }
   },
   "id": "f95e88b20ee78592",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed Naive Bayes Accuracy: 0.7844444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84      1175\n",
      "           1       0.70      0.65      0.68       625\n",
      "\n",
      "    accuracy                           0.78      1800\n",
      "   macro avg       0.76      0.75      0.76      1800\n",
      "weighted avg       0.78      0.78      0.78      1800\n",
      "\n",
      "Fairness Metrics:\n",
      "Male FPR: 0.1622002820874471\n",
      "Male TPR: 0.687374749498998\n",
      "Female FPR: 0.12017167381974249\n",
      "Female TPR: 0.5158730158730159\n",
      "\n",
      "Disparate Impact (DI): 0.539\n",
      "Discrimination Score (DS): -0.175\n",
      "Equal Opportunity Difference (EO): 0.172\n",
      "Equalized Odds (EOdds): 0.042\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['gave birth this year', 'marital status']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english', 'age', 'workinghours']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# the library implementation of MixedNB requires the categorical features to be encoded as integers starting from 0, so we need to encode the education feature separately.\n",
    "le = LabelEncoder()\n",
    "X_train['education'] = le.fit_transform(X_train['education'])\n",
    "X_test['education'] = le.transform(X_test['education'])\n",
    "\n",
    "comb_nb = MixedNB(categorical_features=[1,2,3,5,6]) # indices of categorical features\n",
    "comb_nb.fit(X_train, y_train)\n",
    "comb_nb_preds = comb_nb.predict(X_test)\n",
    "comb_nb_accuracy = accuracy_score(y_test, comb_nb_preds)\n",
    "\n",
    "print(\"Mixed Naive Bayes Accuracy:\", comb_nb_accuracy)\n",
    "print(classification_report(y_test, comb_nb_preds))\n",
    "\n",
    "print_male_female_metrics(comb_nb, X, X_male, X_female, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:07.468250400Z",
     "start_time": "2024-05-01T00:48:07.385840300Z"
    }
   },
   "id": "4dffea56e5c1334f",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Categorical Naive Bayes Model\n",
    "\n",
    "Finally, we can try categorizing the numerical features and training a Categorical Naive Bayes model on a dataset that now has only categorical features.\n",
    "\n",
    "We use the same column exclusion steps as before."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3866426f79e38661"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1175\n",
      "           1       0.67      0.74      0.70       625\n",
      "\n",
      "    accuracy                           0.78      1800\n",
      "   macro avg       0.76      0.77      0.76      1800\n",
      "weighted avg       0.79      0.78      0.78      1800\n",
      "\n",
      "Naive Bayes Accuracy: 0.7811111111111111\n",
      "Fairness Metrics:\n",
      "Male FPR: 0.2834978843441467\n",
      "Male TPR: 0.8336673346693386\n",
      "Female FPR: 0.06437768240343347\n",
      "Female TPR: 0.36507936507936506\n",
      "\n",
      "Disparate Impact (DI): 0.251\n",
      "Discrimination Score (DS): -0.382\n",
      "Equal Opportunity Difference (EO): 0.469\n",
      "Equalized Odds (EOdds): 0.219\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "# we categorize the age and workinghours features, so that all features are categorical\n",
    "X_encoded = X_encoded.drop(columns=['age', 'workinghours'])\n",
    "X_encoded['age'] = pd.cut(X['age'], bins=[0,28,38,49,65,93], labels=['(17-28]', '(28-38]', '(38-49]', '(49-65]', '(65-93]'])\n",
    "X_encoded['workinghours'] = pd.cut(X['workinghours'], bins=[0, 30, 40, 99], labels=['Part-time', 'Full-time', 'Overtime'])\n",
    "\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_cat = CategoricalNB()\n",
    "nb_cat.fit(X_train, y_train)\n",
    "nb_preds = nb_cat.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_preds)\n",
    "\n",
    "print(classification_report(y_test, nb_preds))\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
    "\n",
    "print_male_female_metrics(nb_cat, X, X_male, X_female, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:07.586825Z",
     "start_time": "2024-05-01T00:48:07.464260900Z"
    }
   },
   "id": "e2578ad3831e4c15",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1175\n",
      "           1       0.68      0.68      0.68       625\n",
      "\n",
      "    accuracy                           0.78      1800\n",
      "   macro avg       0.76      0.76      0.76      1800\n",
      "weighted avg       0.78      0.78      0.78      1800\n",
      "\n",
      "Naive Bayes Accuracy: 0.7788888888888889\n",
      "Fairness Metrics:\n",
      "Male FPR: 0.2524682651622003\n",
      "Male TPR: 0.781563126252505\n",
      "Female FPR: 0.03862660944206009\n",
      "Female TPR: 0.2698412698412698\n",
      "\n",
      "Disparate Impact (DI): 0.186\n",
      "Discrimination Score (DS): -0.383\n",
      "Equal Opportunity Difference (EO): 0.512\n",
      "Equalized Odds (EOdds): 0.214\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['age', 'ability to speak english', 'workclass']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# we categorize the age and workinghours features, so that all features are categorical\n",
    "X_encoded = X_encoded.drop(columns=['workinghours'])\n",
    "X_encoded['workinghours'] = pd.cut(X['workinghours'], bins=[0, 30, 40, 99], labels=['Part-time', 'Full-time', 'Overtime'])\n",
    "\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_cat = CategoricalNB()\n",
    "nb_cat.fit(X_train, y_train)\n",
    "nb_preds = nb_cat.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_preds)\n",
    "\n",
    "print(classification_report(y_test, nb_preds))\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
    "\n",
    "print_male_female_metrics(nb_cat, X, X_male, X_female, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:07.642640900Z",
     "start_time": "2024-05-01T00:48:07.559896600Z"
    }
   },
   "id": "c849dd578a43771f",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1175\n",
      "           1       0.67      0.63      0.65       625\n",
      "\n",
      "    accuracy                           0.76      1800\n",
      "   macro avg       0.74      0.73      0.73      1800\n",
      "weighted avg       0.76      0.76      0.76      1800\n",
      "\n",
      "Naive Bayes Accuracy: 0.7622222222222222\n",
      "Fairness Metrics:\n",
      "Male FPR: 0.14950634696755993\n",
      "Male TPR: 0.6372745490981964\n",
      "Female FPR: 0.19957081545064378\n",
      "Female TPR: 0.6190476190476191\n",
      "\n",
      "Disparate Impact (DI): 0.823\n",
      "Discrimination Score (DS): -0.062\n",
      "Equal Opportunity Difference (EO): 0.018\n",
      "Equalized Odds (EOdds): -0.050\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['sex', 'gave birth this year', 'marital status']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# we categorize the age and workinghours features, so that all features are categorical\n",
    "X_encoded = X_encoded.drop(columns=['age', 'workinghours'])\n",
    "X_encoded['age'] = pd.cut(X['age'], bins=[0,28,38,49,65,93], labels=['(17-28]', '(28-38]', '(38-49]', '(49-65]', '(65-93]'])\n",
    "X_encoded['workinghours'] = pd.cut(X['workinghours'], bins=[0, 30, 40, 99], labels=['Part-time', 'Full-time', 'Overtime'])\n",
    "\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_cat = CategoricalNB()\n",
    "nb_cat.fit(X_train, y_train)\n",
    "nb_preds = nb_cat.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_preds)\n",
    "\n",
    "print(classification_report(y_test, nb_preds))\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
    "\n",
    "print_male_female_metrics(nb_cat, X, X_male, X_female, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:07.728126400Z",
     "start_time": "2024-05-01T00:48:07.638650600Z"
    }
   },
   "id": "422f740c40213d15",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1175\n",
      "           1       0.68      0.66      0.67       625\n",
      "\n",
      "    accuracy                           0.78      1800\n",
      "   macro avg       0.75      0.75      0.75      1800\n",
      "weighted avg       0.77      0.78      0.77      1800\n",
      "\n",
      "Naive Bayes Accuracy: 0.7755555555555556\n",
      "Fairness Metrics:\n",
      "Male FPR: 0.17912552891396333\n",
      "Male TPR: 0.7054108216432866\n",
      "Female FPR: 0.13304721030042918\n",
      "Female TPR: 0.4603174603174603\n",
      "\n",
      "Disparate Impact (DI): 0.511\n",
      "Discrimination Score (DS): -0.194\n",
      "Equal Opportunity Difference (EO): 0.245\n",
      "Equalized Odds (EOdds): 0.046\n"
     ]
    }
   ],
   "source": [
    "X_encoded = X.copy()\n",
    "columns_to_exclude = ['gave birth this year', 'marital status']\n",
    "X_encoded = X_encoded.drop(columns=columns_to_exclude)\n",
    "# we categorize the age and workinghours features, so that all features are categorical\n",
    "X_encoded = X_encoded.drop(columns=['age', 'workinghours'])\n",
    "X_encoded['age'] = pd.cut(X['age'], bins=[0,28,38,49,65,93], labels=['(17-28]', '(28-38]', '(38-49]', '(49-65]', '(65-93]'])\n",
    "X_encoded['workinghours'] = pd.cut(X['workinghours'], bins=[0, 30, 40, 99], labels=['Part-time', 'Full-time', 'Overtime'])\n",
    "\n",
    "# encode all categorical features using label encoding\n",
    "le = LabelEncoder()\n",
    "for col in X_encoded.columns:\n",
    "    if col not in ['education', 'ability to speak english']:\n",
    "        X_encoded[col] = le.fit_transform(X[col])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_cat = CategoricalNB()\n",
    "nb_cat.fit(X_train, y_train)\n",
    "nb_preds = nb_cat.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_preds)\n",
    "\n",
    "print(classification_report(y_test, nb_preds))\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
    "\n",
    "print_male_female_metrics(nb_cat, X, X_male, X_female, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:07.794155300Z",
     "start_time": "2024-05-01T00:48:07.714163300Z"
    }
   },
   "id": "ada0d2f3626614e5",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Naive Bayes models do not have many hyperparameters to tune. We won't do any hyperparameter tuning for any models here."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9423e3ffd4469d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving the Model(s)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6ce32c604f62593"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# save model\n",
    "save_model(nb_model, '../output/saved_models/naive_bayes_model.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T00:48:07.809192100Z",
     "start_time": "2024-05-01T00:48:07.794155300Z"
    }
   },
   "id": "eac15450e6ee09ea",
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
