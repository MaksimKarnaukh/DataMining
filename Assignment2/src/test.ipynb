{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:15.972728800Z",
     "start_time": "2024-05-06T19:14:15.575981300Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from helper.helper_functions import load_dataset, save_dataset, load_model, encode_nominal_features, encode_all_features, get_features_and_target\n",
    "\n",
    "from scipy.stats import entropy\n",
    "from scipy.special import kl_div\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bfa0fafb29cd66c"
  },
  {
   "cell_type": "code",
   "source": [
    "data_original = load_dataset(\"../data/assignment2_income_cleaned.xlsx\")\n",
    "data_test = load_dataset(\"../data/assignment2_test.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:19.628213100Z",
     "start_time": "2024-05-06T19:14:15.976708900Z"
    }
   },
   "id": "f02c765b61d0c1fc",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Data Inspection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b809c36b73889032"
  },
  {
   "cell_type": "code",
   "source": [
    "data_test.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:19.642288100Z",
     "start_time": "2024-05-06T19:14:19.629210300Z"
    }
   },
   "id": "9af99ecf9c225a99",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# check the amount of missing values in the 'gave birth this year' column for the age bins (17-28, 28-38, 38-49, 49-65, 65-93) for females\n",
    "female_data = data_test[data_test['sex'] == 'Female']\n",
    "female_data['gave birth this year'][female_data['gave birth this year'].isnull()].groupby(\n",
    "    pd.cut(female_data['age'], bins=[0, 28, 38, 49, 65, 93]), observed=False).size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:19.709570500Z",
     "start_time": "2024-05-06T19:14:19.642288100Z"
    }
   },
   "id": "eadf3b9a5c8593e",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We impute the missing values in the 'ability to speak english' and 'gave birth this year' columns in the same manner as before."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78dd7ea69fed8c6"
  },
  {
   "cell_type": "code",
   "source": [
    "data_test['ability to speak english'] = data_test['ability to speak english'].fillna(0)\n",
    "data_test['gave birth this year'] = data_test['gave birth this year'].fillna('No')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:19.711564600Z",
     "start_time": "2024-05-06T19:14:19.660594100Z"
    }
   },
   "id": "8a9861893e3d903a",
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Data Distribution Discrepancy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76e31a65602a7b9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the KL divergence to measure the distribution discrepancy between the training and test sets, we want to identify the features that have the highest discrepancy and calculate the mean discrepancy between the two datasets."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6958e3026861097"
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_kl_divergence(train_set: pd.DataFrame, test_set: pd.DataFrame, numerical_features: list[str]):\n",
    "    \"\"\"\n",
    "    Compute KL divergence between the distributions of features in the training and test sets.\n",
    "    :param train_set: DataFrame containing features of the training set.\n",
    "    :param test_set: DataFrame containing features of the test set.\n",
    "    :param numerical_features: List of numerical features.\n",
    "    :return: Array of KL divergence values for each feature in Series format.\n",
    "    \"\"\"\n",
    "\n",
    "    kl_divergences = []\n",
    "    train_set = train_set[test_set.columns]\n",
    "    for feature in test_set.columns:  # Use test set columns since it has no target label\n",
    "        \n",
    "        # code below seems to produce slightly different results.\n",
    "        # if feature not in numerical_features:  # Handle categorical features\n",
    "        #     train_dist = train_set[feature].value_counts(normalize=True)\n",
    "        #     test_dist = test_set[feature].value_counts(normalize=True)\n",
    "        # \n",
    "        #     # Ensure all possible values are represented in both distributions\n",
    "        #     all_values = set(train_dist.index) | set(test_dist.index)\n",
    "        #     for value in all_values:\n",
    "        #         if value not in train_dist.index:\n",
    "        #             train_dist[value] = 0.000001  # Add a small non-zero count for missing value\n",
    "        #         if value not in test_dist.index:\n",
    "        #             test_dist[value] = 0.000001  # Add a small non-zero count for missing value\n",
    "        # else:  # Handle numerical features\n",
    "        #     train_dist, _ = np.histogram(train_set[feature], bins=10, density=True)\n",
    "        #     test_dist, _ = np.histogram(test_set[feature], bins=10, density=True)\n",
    "        # \n",
    "        # assert train_dist.shape == test_dist.shape\n",
    "        # \n",
    "        # # Normalizing\n",
    "        # train_dist /= np.sum(train_dist)\n",
    "        # test_dist /= np.sum(test_dist)\n",
    "        # \n",
    "        # # KL divergence\n",
    "        # kl_divergence = entropy(train_dist, test_dist)\n",
    "        # kl_divergences.append(kl_divergence)\n",
    "        \n",
    "        kl_divergences.append(np.sum(kl_div(train_set[feature].value_counts(normalize=True).sort_index(), test_set[feature].value_counts(normalize=True).sort_index())))\n",
    "\n",
    "    return pd.Series(kl_divergences, index=test_set.columns)\n",
    "\n",
    "\n",
    "def aggregate_kl_divergence(kl_divergences: np.ndarray | pd.Series):\n",
    "    \"\"\"\n",
    "    Aggregate KL divergence values across all features.\n",
    "    :param kl_divergences: Array of KL divergence values for each feature.\n",
    "    :return: Overall measure of distribution discrepancy (in this case the mean value).\n",
    "    \"\"\"\n",
    "    if isinstance(kl_divergences, np.ndarray):\n",
    "        return np.mean(kl_divergences)\n",
    "    elif isinstance(kl_divergences, pd.Series):\n",
    "        return kl_divergences.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:19.732508200Z",
     "start_time": "2024-05-06T19:14:19.680603200Z"
    }
   },
   "id": "f363d63673834c08",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_original_train, data_original_val = train_test_split(data_original, test_size=0.2, random_state=42)\n",
    "kl_divergences = compute_kl_divergence(data_original, data_test, ['age', 'workinghours'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:19.875194Z",
     "start_time": "2024-05-06T19:14:19.690112Z"
    }
   },
   "id": "6dccd6e8de5dbdd2",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "kl_divergences_df = pd.DataFrame({'KL Divergence': kl_divergences})\n",
    "kl_divergences_df.index = kl_divergences.index  # Set DataFrame index to match Series index\n",
    "kl_divergences_df = kl_divergences_df.sort_values(by='KL Divergence', ascending=False)\n",
    "kl_divergences_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:19.907719500Z",
     "start_time": "2024-05-06T19:14:19.876191Z"
    }
   },
   "id": "f472e52be84d24b3",
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "aggregate_kl_divergence(kl_divergences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:19.925182700Z",
     "start_time": "2024-05-06T19:14:19.901436400Z"
    }
   },
   "id": "1c6bb63f515e365d",
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Data Feature Encoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15a5cd08e3d1703a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we encode the features of the test data using the same encoding as the training data. We exclude the columns that were not used in the model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c43fbc74808578d3"
  },
  {
   "cell_type": "code",
   "source": [
    "# drop columns that our model does not use\n",
    "columns_to_exclude = ['sex', 'gave birth this year', 'marital status']\n",
    "data_test_sexexcl = data_test.drop(columns=columns_to_exclude)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:20.015039300Z",
     "start_time": "2024-05-06T19:14:19.913214500Z"
    }
   },
   "id": "266d287d2e19493",
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "nominal_features_lc = list(\n",
    "    {'workclass', 'marital status', 'gave birth this year', 'sex', 'occupation'} - set(\n",
    "        columns_to_exclude))  # low cardinality features\n",
    "nominal_features_hc = []\n",
    "\n",
    "# Encoded test set\n",
    "data_test_encoded = encode_nominal_features(data_test_sexexcl, nominal_features_lc, nominal_features_hc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:20.044505200Z",
     "start_time": "2024-05-06T19:14:19.933163100Z"
    }
   },
   "id": "2f5f4746649c4f76",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate predictions for test data using the best model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20adaf68374ff414"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We load the best model and generate predictions for the test data. We also save the predictions to a .xlsx file."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "512b32cd4e0028fa"
  },
  {
   "cell_type": "code",
   "source": [
    "# load the best model\n",
    "model = load_model('../output/saved_models/dt_model_sexexcl_ffs_tuned_fair.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:20.201121800Z",
     "start_time": "2024-05-06T19:14:19.968092500Z"
    }
   },
   "id": "495a0e1422e9ee46",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Get the feature names used during training\n",
    "train_features = model.feature_names_in_\n",
    "data_test_reordered = data_test_encoded[train_features]\n",
    "data_test_encoded = data_test_reordered\n",
    "# predict the test data\n",
    "y_pred = model.predict(data_test_encoded)\n",
    "# save the predictions\n",
    "y_pred = pd.DataFrame(y_pred, columns=['income'])\n",
    "save_dataset(y_pred, '../output/test_predictions/best_model_predictions.xlsx', index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:21.441907800Z",
     "start_time": "2024-05-06T19:14:20.180178500Z"
    }
   },
   "id": "59dff71094fa492b",
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "p = load_dataset('../output/test_predictions/best_model_predictions.xlsx')\n",
    "print(len(p), len(y_pred)) # the lengths should be the same\n",
    "# see if the predictions were saved correctly\n",
    "differing_values = (y_pred['income'] != p['income']).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:21.520208500Z",
     "start_time": "2024-05-06T19:14:21.407001900Z"
    }
   },
   "id": "1f0ac6286245d790",
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Little check to see if the predictions were saved correctly."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32d21b5be5228aca"
  },
  {
   "cell_type": "code",
   "source": [
    "differing_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:21.523200200Z",
     "start_time": "2024-05-06T19:14:21.512229600Z"
    }
   },
   "id": "b619a23b51b4ce7e",
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inspection of the predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b353dbf70581a28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We inspect the predictions to see the distribution of low and high income predictions. We do the same per sex."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "501c970c1096ce74"
  },
  {
   "cell_type": "code",
   "source": [
    "# Count amount of low (0) and high (1) income predictions\n",
    "predicted_1 = (y_pred == 1).sum()\n",
    "predicted_0 = (y_pred == 0).sum()\n",
    "\n",
    "# Create a DataFrame\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Prediction': [1, 0],\n",
    "    'Count': [predicted_1, predicted_0]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:21.625343100Z",
     "start_time": "2024-05-06T19:14:21.521205700Z"
    }
   },
   "id": "553be251d85fbaf5",
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:21.652271500Z",
     "start_time": "2024-05-06T19:14:21.544654Z"
    }
   },
   "id": "c986d2f05fb9e6e4",
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Filter predictions for males\n",
    "male_predictions = y_pred[data_test['sex'] == 'Male']\n",
    "\n",
    "male_predicted_1 = (male_predictions == 1).sum()\n",
    "male_predicted_0 = (male_predictions == 0).sum()\n",
    "\n",
    "# Filter predictions for females\n",
    "female_predictions = y_pred[data_test['sex'] == 'Female']\n",
    "\n",
    "female_predicted_1 = (female_predictions == 1).sum()\n",
    "female_predicted_0 = (female_predictions == 0).sum()\n",
    "\n",
    "predictions_df_mf = pd.DataFrame({\n",
    "    'Sex': ['Male', 'Female'],\n",
    "    'Predicted_1': [male_predicted_1, female_predicted_1],\n",
    "    'Predicted_0': [male_predicted_0, female_predicted_0]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:21.673237700Z",
     "start_time": "2024-05-06T19:14:21.604399800Z"
    }
   },
   "id": "604b0c880ec4b6d5",
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "predictions_df_mf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:21.679731500Z",
     "start_time": "2024-05-06T19:14:21.649280400Z"
    }
   },
   "id": "8a2ad5053d153e78",
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "columns_to_exclude = ['sex', 'gave birth this year', 'marital status']\n",
    "X_original, y_original = get_features_and_target(data_original, 'income')\n",
    "X_original = X_original.drop(columns=columns_to_exclude)\n",
    "X_original_encoded, y_original_encoded = encode_all_features(X_original, y_original, columns_to_exclude)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_original_encoded, y_original_encoded, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:21.767693500Z",
     "start_time": "2024-05-06T19:14:21.671243100Z"
    }
   },
   "id": "618845aec61830f1",
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Estimating the accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51b63d1bd5dd5f63"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will express the accuracy of our best model (on the validation set) as a weighted sum of accuracies of the feature values. The next step is then to calculate the feature value distribution for the test set, so we can get those probabilities. We can plug in these probabilities (corresponding to their value of course) in the formula using the same accuracies as before, since we assume the accuracies stay roughly the same for our model and only the value distribution changes. Ultimately, we get the weighted accuracy for our test set."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed16ee745b802472"
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_accuracy_by_feature_value(model: any, feature_name: str, X_test: pd.DataFrame, y_test: pd.Series):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of the model on the test set for each unique value of a feature.\n",
    "    :param model: model\n",
    "    :param feature_name: name of the feature for the weighted accuracy\n",
    "    :param X_test: validation set features\n",
    "    :param y_test: validation set target\n",
    "    :return: dictionary of (prob, accuracy) for each unique value of the feature\n",
    "    \"\"\"\n",
    "    feature_values = X_test[feature_name].unique()\n",
    "    accuracies = {}\n",
    "    for value in feature_values:\n",
    "        # Filter the data for the current feature value\n",
    "        subset_data = X_test[X_test[feature_name] == value]\n",
    "        # Get the probability of the current feature value\n",
    "        prob = len(subset_data) / len(X_test)\n",
    "        y_subset = y_test.loc[subset_data.index]\n",
    "        \n",
    "        # Get the feature names used during training\n",
    "        train_features = model.feature_names_in_\n",
    "        data_test_reordered = subset_data[train_features]\n",
    "        subset_data = data_test_reordered\n",
    "    \n",
    "        y_pred = model.predict(subset_data)\n",
    "        accuracy = accuracy_score(y_subset, y_pred)\n",
    "        \n",
    "        accuracies[value] = prob, accuracy\n",
    "        \n",
    "    assert 0.99 < sum([prob for prob, _ in accuracies.values()]) <= 1\n",
    "    return accuracies"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:21.819555200Z",
     "start_time": "2024-05-06T19:14:21.715660900Z"
    }
   },
   "id": "c7bbe7a97be2b19c",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "feature_name = 'workinghours'\n",
    "feature_values = X_test[feature_name].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:21.931256300Z",
     "start_time": "2024-05-06T19:14:21.738771300Z"
    }
   },
   "id": "74ea616fe9440df3",
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "accuracy_by_value = compute_accuracy_by_feature_value(model, feature_name, X_test, y_test)\n",
    "# print(accuracy_by_value) # uncomment to see the probabilities (~weights) and accuracies"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:22.154535800Z",
     "start_time": "2024-05-06T19:14:21.761709800Z"
    }
   },
   "id": "5d068173981b1d52",
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below, we calculate the weighted accuracy for the 'workinghours' feature for the validation set (from the original dataset)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29fdb0f15039c9e6"
  },
  {
   "cell_type": "code",
   "source": [
    "sum_of_prob = sum([accuracy_by_value[key][0] for key in accuracy_by_value])\n",
    "# get the weighted accuracy by summing the product of the probability and accuracy\n",
    "weighted_accuracy = sum([accuracy_by_value[key][0] * accuracy_by_value[key][1] for key in accuracy_by_value]) / sum_of_prob\n",
    "print(\"Weighted Accuracy:\", weighted_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:22.156530100Z",
     "start_time": "2024-05-06T19:14:22.033998600Z"
    }
   },
   "id": "9f8686aec85a5b41",
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can then calculate the weighted accuracy for the 'workinghours' feature for the test set."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "829c1e15607a7684"
  },
  {
   "cell_type": "code",
   "source": [
    "# Next, calculate the probability distribution of feature values in X_test\n",
    "feature_distribution = data_test[feature_name].value_counts(normalize=True)\n",
    "# print(feature_distribution) # uncomment to see the probabilities\n",
    "\n",
    "weighted_accuracy = 0\n",
    "for value in feature_values:\n",
    "    # Get the probability and accuracy of the current feature value in test data\n",
    "    prob = feature_distribution.get(value, 0.0000001)\n",
    "    accuracy = accuracy_by_value.get(value, (prob, weighted_accuracy))[1]  # 0 as default accuracy if value not found\n",
    "    # Update the weighted accuracy by adding the product of probability and accuracy\n",
    "    weighted_accuracy += prob * accuracy\n",
    "\n",
    "# Finally, print or return the weighted accuracy\n",
    "print(\"Weighted Accuracy:\", weighted_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T19:14:22.160519300Z",
     "start_time": "2024-05-06T19:14:22.041817300Z"
    }
   },
   "id": "c5232b836b0980b3",
   "execution_count": 32,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
