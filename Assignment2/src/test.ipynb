{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:14:59.618902100Z",
     "start_time": "2024-05-06T01:14:59.347331800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from helper.helper_functions import load_dataset, save_dataset, load_model, encode_nominal_features\n",
    "\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bfa0fafb29cd66c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_original = load_dataset(\"../data/assignment2_income_cleaned.xlsx\")\n",
    "data_test = load_dataset(\"../data/assignment2_test.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:01.797117Z",
     "start_time": "2024-05-06T01:14:59.618902100Z"
    }
   },
   "id": "f02c765b61d0c1fc",
   "execution_count": 355
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Data Inspection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b809c36b73889032"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       2000 non-null   int64  \n",
      " 1   workclass                 2000 non-null   object \n",
      " 2   education                 2000 non-null   int64  \n",
      " 3   marital status            2000 non-null   object \n",
      " 4   occupation                2000 non-null   object \n",
      " 5   workinghours              2000 non-null   int64  \n",
      " 6   sex                       2000 non-null   object \n",
      " 7   ability to speak english  105 non-null    float64\n",
      " 8   gave birth this year      562 non-null    object \n",
      "dtypes: float64(1), int64(3), object(5)\n",
      "memory usage: 140.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data_test.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:01.808756300Z",
     "start_time": "2024-05-06T01:15:01.798114500Z"
    }
   },
   "id": "9af99ecf9c225a99",
   "execution_count": 356
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "age\n(0, 28]       0\n(28, 38]      0\n(38, 49]      0\n(49, 65]    230\n(65, 93]     55\nName: gave birth this year, dtype: int64"
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the amount of missing values in the 'gave birth this year' column for the age bins (17-28, 28-38, 38-49, 49-65, 65-93) for females\n",
    "female_data = data_test[data_test['sex'] == 'Female']\n",
    "female_data['gave birth this year'][female_data['gave birth this year'].isnull()].groupby(\n",
    "    pd.cut(female_data['age'], bins=[0, 28, 38, 49, 65, 93]), observed=False).size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:01.859095800Z",
     "start_time": "2024-05-06T01:15:01.808756300Z"
    }
   },
   "id": "eadf3b9a5c8593e",
   "execution_count": 357
  },
  {
   "cell_type": "markdown",
   "source": [
    "We impute the missing values in the 'ability to speak english' and 'gave birth this year' columns in the same manner as before."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78dd7ea69fed8c6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_test['ability to speak english'] = data_test['ability to speak english'].fillna(0)\n",
    "data_test['gave birth this year'] = data_test['gave birth this year'].fillna('No')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:01.860092900Z",
     "start_time": "2024-05-06T01:15:01.825692500Z"
    }
   },
   "id": "8a9861893e3d903a",
   "execution_count": 358
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Data Distribution Discrepancy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76e31a65602a7b9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the KL divergence to measure the distribution discrepancy between the training and test sets, we want to identify the features that have the highest discrepancy and calculate the mean discrepancy between the two datasets."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6958e3026861097"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_kl_divergence(train_set: pd.DataFrame, test_set: pd.DataFrame, numerical_features: list[str]):\n",
    "    \"\"\"\n",
    "    Compute KL divergence between the distributions of features in the training and test sets.\n",
    "    :param train_set: DataFrame containing features of the training set.\n",
    "    :param test_set: DataFrame containing features of the test set.\n",
    "    :param numerical_features: List of numerical features.\n",
    "    :return: Array of KL divergence values for each feature in Series format.\n",
    "    \"\"\"\n",
    "\n",
    "    kl_divergences = []\n",
    "    for feature in test_set.columns:  # Use test set columns since it has no target label\n",
    "        if feature not in numerical_features:  # Handle categorical features\n",
    "            train_dist = train_set[feature].value_counts(normalize=True)\n",
    "            test_dist = test_set[feature].value_counts(normalize=True)\n",
    "\n",
    "            # Ensure all possible values are represented in both distributions\n",
    "            all_values = set(train_dist.index) | set(test_dist.index)\n",
    "            for value in all_values:\n",
    "                if value not in train_dist.index:\n",
    "                    train_dist[value] = 0.000001  # Add a small non-zero count for missing value\n",
    "                if value not in test_dist.index:\n",
    "                    test_dist[value] = 0.000001  # Add a small non-zero count for missing value\n",
    "        else:  # Handle numerical features\n",
    "            train_dist, _ = np.histogram(train_set[feature], bins=10, density=True)\n",
    "            test_dist, _ = np.histogram(test_set[feature], bins=10, density=True)\n",
    "\n",
    "        assert train_dist.shape == test_dist.shape\n",
    "\n",
    "        # Normalizing\n",
    "        train_dist /= np.sum(train_dist)\n",
    "        test_dist /= np.sum(test_dist)\n",
    "\n",
    "        # KL divergence\n",
    "        kl_divergence = entropy(train_dist, test_dist)\n",
    "        kl_divergences.append(kl_divergence)\n",
    "\n",
    "    return pd.Series(kl_divergences, index=test_set.columns)\n",
    "\n",
    "\n",
    "def aggregate_kl_divergence(kl_divergences: np.ndarray | pd.Series):\n",
    "    \"\"\"\n",
    "    Aggregate KL divergence values across all features.\n",
    "    :param kl_divergences: Array of KL divergence values for each feature.\n",
    "    :return: Overall measure of distribution discrepancy (in this case the mean value).\n",
    "    \"\"\"\n",
    "    if isinstance(kl_divergences, np.ndarray):\n",
    "        return np.mean(kl_divergences)\n",
    "    elif isinstance(kl_divergences, pd.Series):\n",
    "        return kl_divergences.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:01.862087700Z",
     "start_time": "2024-05-06T01:15:01.831547Z"
    }
   },
   "id": "f363d63673834c08",
   "execution_count": 359
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                          KL Divergence\nworkinghours                   0.290940\neducation                      0.068560\nage                            0.047542\noccupation                     0.028383\nsex                            0.017073\nworkclass                      0.008632\nability to speak english       0.002802\nmarital status                 0.001831\ngave birth this year           0.000019",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>KL Divergence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>workinghours</th>\n      <td>0.290940</td>\n    </tr>\n    <tr>\n      <th>education</th>\n      <td>0.068560</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>0.047542</td>\n    </tr>\n    <tr>\n      <th>occupation</th>\n      <td>0.028383</td>\n    </tr>\n    <tr>\n      <th>sex</th>\n      <td>0.017073</td>\n    </tr>\n    <tr>\n      <th>workclass</th>\n      <td>0.008632</td>\n    </tr>\n    <tr>\n      <th>ability to speak english</th>\n      <td>0.002802</td>\n    </tr>\n    <tr>\n      <th>marital status</th>\n      <td>0.001831</td>\n    </tr>\n    <tr>\n      <th>gave birth this year</th>\n      <td>0.000019</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergences = compute_kl_divergence(data_original, data_test, ['age', 'workinghours'])\n",
    "kl_divergences_df = pd.DataFrame({'KL Divergence': kl_divergences})\n",
    "kl_divergences_df = kl_divergences_df.sort_values(by='KL Divergence', ascending=False)\n",
    "kl_divergences_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:01.913386900Z",
     "start_time": "2024-05-06T01:15:01.846130800Z"
    }
   },
   "id": "77bba072f049d84a",
   "execution_count": 360
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.051753484383575445"
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_kl_divergence(kl_divergences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:01.915381700Z",
     "start_time": "2024-05-06T01:15:01.885356900Z"
    }
   },
   "id": "1c6bb63f515e365d",
   "execution_count": 361
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Data Feature Encoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15a5cd08e3d1703a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we encode the features of the test data using the same encoding as the training data. We exclude the columns that were not used in the model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c43fbc74808578d3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# drop columns that our model does not use\n",
    "columns_to_exclude = ['sex', 'gave birth this year', 'marital status']\n",
    "data_test_sexexcl = data_test.drop(columns=columns_to_exclude)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:01.917376200Z",
     "start_time": "2024-05-06T01:15:01.891945100Z"
    }
   },
   "id": "266d287d2e19493",
   "execution_count": 362
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nominal_features_lc = list(\n",
    "    {'workclass', 'marital status', 'gave birth this year', 'sex', 'occupation'} - set(\n",
    "        columns_to_exclude))  # low cardinality features\n",
    "nominal_features_hc = []\n",
    "\n",
    "# Encoded test set\n",
    "data_test_encoded = encode_nominal_features(data_test_sexexcl, nominal_features_lc, nominal_features_hc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:01.918373200Z",
     "start_time": "2024-05-06T01:15:01.900177900Z"
    }
   },
   "id": "2f5f4746649c4f76",
   "execution_count": 363
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate predictions for test data using the best model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20adaf68374ff414"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load the best model\n",
    "model = load_model('../output/saved_models/dt_model_sexexcl_ffs_tuned_fair.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:01.974791500Z",
     "start_time": "2024-05-06T01:15:01.914384700Z"
    }
   },
   "id": "495a0e1422e9ee46",
   "execution_count": 364
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get the feature names used during training\n",
    "train_features = model.feature_names_in_\n",
    "data_test_reordered = data_test_encoded[train_features]\n",
    "data_test_encoded = data_test_reordered\n",
    "# predict the test data\n",
    "y_pred = model.predict(data_test_encoded)\n",
    "# save the predictions\n",
    "y_pred = pd.DataFrame(y_pred, columns=['income'])\n",
    "save_dataset(y_pred, '../output/test_predictions/best_model_predictions.xlsx', index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:02.136261700Z",
     "start_time": "2024-05-06T01:15:01.923928200Z"
    }
   },
   "id": "59dff71094fa492b",
   "execution_count": 365
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000\n"
     ]
    }
   ],
   "source": [
    "p = load_dataset('../output/test_predictions/best_model_predictions.xlsx')\n",
    "print(len(p), len(y_pred)) # the lengths should be the same\n",
    "# see if the predictions were saved correctly\n",
    "differing_values = (y_pred['income'] != p['income']).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:02.243524800Z",
     "start_time": "2024-05-06T01:15:02.115317500Z"
    }
   },
   "id": "1f0ac6286245d790",
   "execution_count": 366
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differing_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:02.247513500Z",
     "start_time": "2024-05-06T01:15:02.239703Z"
    }
   },
   "id": "b619a23b51b4ce7e",
   "execution_count": 367
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inspection of the predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b353dbf70581a28"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Count amount of low (0) and high (1) income predictions\n",
    "predicted_1 = (y_pred == 1).sum()\n",
    "predicted_0 = (y_pred == 0).sum()\n",
    "\n",
    "# Create a DataFrame\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Prediction': [1, 0],\n",
    "    'Count': [predicted_1, predicted_0]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:02.258358100Z",
     "start_time": "2024-05-06T01:15:02.247513500Z"
    }
   },
   "id": "553be251d85fbaf5",
   "execution_count": 368
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "income\n1         1051\n0          949\nName: count, dtype: int64"
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:02.322102600Z",
     "start_time": "2024-05-06T01:15:02.254367Z"
    }
   },
   "id": "c986d2f05fb9e6e4",
   "execution_count": 369
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Filter predictions for males\n",
    "male_predictions = y_pred[data_test['sex'] == 'Male']\n",
    "\n",
    "male_predicted_1 = (male_predictions == 1).sum()\n",
    "male_predicted_0 = (male_predictions == 0).sum()\n",
    "\n",
    "# Filter predictions for females\n",
    "female_predictions = y_pred[data_test['sex'] == 'Female']\n",
    "\n",
    "female_predicted_1 = (female_predictions == 1).sum()\n",
    "female_predicted_0 = (female_predictions == 0).sum()\n",
    "\n",
    "predictions_df_mf = pd.DataFrame({\n",
    "    'Sex': ['Male', 'Female'],\n",
    "    'Predicted_1': [male_predicted_1, female_predicted_1],\n",
    "    'Predicted_0': [male_predicted_0, female_predicted_0]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:02.328594800Z",
     "start_time": "2024-05-06T01:15:02.266537500Z"
    }
   },
   "id": "604b0c880ec4b6d5",
   "execution_count": 370
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      Sex                 Predicted_1                 Predicted_0\n0    Male  income    666\ndtype: int64  income    487\ndtype: int64\n1  Female  income    385\ndtype: int64  income    462\ndtype: int64",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Predicted_1</th>\n      <th>Predicted_0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Male</td>\n      <td>income    666\ndtype: int64</td>\n      <td>income    487\ndtype: int64</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Female</td>\n      <td>income    385\ndtype: int64</td>\n      <td>income    462\ndtype: int64</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df_mf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:02.343554800Z",
     "start_time": "2024-05-06T01:15:02.280957100Z"
    }
   },
   "id": "8a2ad5053d153e78",
   "execution_count": 371
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from helper.helper_functions import encode_all_features\n",
    "from helper.helper_functions import get_features_and_target\n",
    "\n",
    "columns_to_exclude = ['sex', 'gave birth this year', 'marital status']\n",
    "X_original, y_original = get_features_and_target(data_original, 'income')\n",
    "X_original = X_original.drop(columns=columns_to_exclude)\n",
    "X_original_encoded, y_original_encoded = encode_all_features(X_original, y_original, columns_to_exclude)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_original_encoded, y_original_encoded, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:02.372478500Z",
     "start_time": "2024-05-06T01:15:02.291750400Z"
    }
   },
   "id": "618845aec61830f1",
   "execution_count": 372
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Estimating the accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51b63d1bd5dd5f63"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import product\n",
    "\n",
    "def compute_accuracy(train_set, test_set, model, features):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of the model on the test set using feature value distributions.\n",
    "    \n",
    "    Args:\n",
    "        train_set (pd.DataFrame): DataFrame containing features of the original dataset.\n",
    "        test_set (pd.DataFrame): DataFrame containing features of the test set.\n",
    "        model: Trained classification model.\n",
    "        features (list): List of feature names to consider.\n",
    "    \n",
    "    Returns:\n",
    "        accuracy (float): Estimated accuracy of the model on the test set.\n",
    "    \"\"\"\n",
    "    # Get unique values for each feature from the original dataset\n",
    "    feature_values = {}\n",
    "    for feature in features:\n",
    "        feature_values[feature] = train_set[feature].unique()\n",
    "    \n",
    "    # Compute accuracy for each combination of feature values\n",
    "    total_weight = 0\n",
    "    total_accuracy = 0\n",
    "    for values in product(*feature_values.values()):\n",
    "        # Filter rows with the specific combination of feature values\n",
    "        train_subset = train_set.copy()\n",
    "        test_subset = test_set.copy()\n",
    "        for feature, value in zip(features, values):\n",
    "            train_subset = train_subset[train_subset[feature] == value]\n",
    "            test_subset = test_subset[test_subset[feature] == value]\n",
    "        \n",
    "        # Calculate accuracy on the original dataset\n",
    "        original_accuracy = accuracy_score(train_subset['income'], model.predict(train_subset.drop(columns=['income'])))\n",
    "        \n",
    "        # # Calculate accuracy on the test set\n",
    "        # test_accuracy = model.evaluate(test_subset.drop(columns=['label']), test_subset['label'])\n",
    "        dist_1 = len(train_subset)\n",
    "        dist_2 = len(test_subset)\n",
    "        \n",
    "        # Compute weight based on KL divergence between feature value distributions\n",
    "        weight = compute_kl_divergence(train_subset, test_subset)\n",
    "        \n",
    "        # Update total accuracy and weight\n",
    "        total_weight += weight\n",
    "        total_accuracy += weight * original_accuracy\n",
    "    \n",
    "    # Normalize total accuracy by total weight\n",
    "    accuracy = total_accuracy / total_weight\n",
    "    return accuracy\n",
    "\n",
    "# estimated_accuracy = compute_accuracy(data_original, data_test, model, ['workinghours', 'education', 'age'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:02.390429500Z",
     "start_time": "2024-05-06T01:15:02.308853300Z"
    }
   },
   "id": "85db7e901c039a6",
   "execution_count": 373
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_accuracy_by_feature_value(model, feature_name, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of the model on the test set for each unique value of a feature.\n",
    "    :param model: \n",
    "    :param feature_name: \n",
    "    :param feature_values: \n",
    "    :param X_test: \n",
    "    :param y_test: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    feature_values = X_test[feature_name].unique()\n",
    "    accuracies = {}\n",
    "    for value in feature_values:\n",
    "        # Filter the data for the current feature value\n",
    "        subset_data = X_test[X_test[feature_name] == value]\n",
    "        # Get the probability of the current feature value\n",
    "        prob = len(subset_data) / len(X_test)\n",
    "        y_subset = y_test.loc[subset_data.index]\n",
    "        \n",
    "        # Get the feature names used during training\n",
    "        train_features = model.feature_names_in_\n",
    "        data_test_reordered = subset_data[train_features]\n",
    "        subset_data = data_test_reordered\n",
    "    \n",
    "        y_pred = model.predict(subset_data)\n",
    "        accuracy = accuracy_score(y_subset, y_pred)\n",
    "        \n",
    "        accuracies[value] = prob, accuracy\n",
    "        \n",
    "    assert 0.99 < sum([prob for prob, _ in accuracies.values()]) <= 1\n",
    "    return accuracies"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:02.405389300Z",
     "start_time": "2024-05-06T01:15:02.342557800Z"
    }
   },
   "id": "c7bbe7a97be2b19c",
   "execution_count": 374
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Accuracy: 0.7616666666666664\n"
     ]
    }
   ],
   "source": [
    "feature_name = 'workinghours'\n",
    "feature_values = X_test[feature_name].unique()\n",
    "accuracy_by_value = compute_accuracy_by_feature_value(model, feature_name, X_test, y_test)\n",
    "sum_of_prob = sum([accuracy_by_value[key][0] for key in accuracy_by_value])\n",
    "# get the weighted accuracy by summing the product of the probability and accuracy\n",
    "weighted_accuracy = sum([accuracy_by_value[key][0] * accuracy_by_value[key][1] for key in accuracy_by_value]) / sum_of_prob\n",
    "print(\"Weighted Accuracy:\", weighted_accuracy)\n",
    "# print(accuracy_by_value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:02.628838Z",
     "start_time": "2024-05-06T01:15:02.346548Z"
    }
   },
   "id": "9f8686aec85a5b41",
   "execution_count": 375
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Accuracy: 0.7048779149273225\n"
     ]
    }
   ],
   "source": [
    "# Next, calculate the probability distribution of feature values in X_test\n",
    "feature_distribution = data_test[feature_name].value_counts(normalize=True)\n",
    "# print(feature_distribution)\n",
    "\n",
    "weighted_accuracy = 0\n",
    "for value in feature_values:\n",
    "    # Get the probability and accuracy of the current feature value in X_test\n",
    "    prob = feature_distribution.get(value, 0.0000001)\n",
    "    accuracy = accuracy_by_value.get(value, (prob, weighted_accuracy))[1]  # 0 as default accuracy if value not found\n",
    "    # Update the weighted accuracy by adding the product of probability and accuracy\n",
    "    weighted_accuracy += prob * accuracy\n",
    "\n",
    "# Finally, print or return the weighted accuracy\n",
    "print(\"Weighted Accuracy:\", weighted_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T01:15:02.638294800Z",
     "start_time": "2024-05-06T01:15:02.628838Z"
    }
   },
   "id": "c5232b836b0980b3",
   "execution_count": 376
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
