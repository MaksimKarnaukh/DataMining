{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:08.920692Z",
     "start_time": "2024-05-23T23:55:08.915016Z"
    }
   },
   "source": [
    "import importlib\n",
    "import data_preprocessor\n",
    "import helper_functions\n",
    "import cluster_validation as cv\n",
    "import cluster_plotting as cp\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "importlib.reload(data_preprocessor)\n",
    "importlib.reload(helper_functions)\n",
    "importlib.reload(cv)\n",
    "importlib.reload(cp)\n",
    "\n",
    "from helper_functions import load_dataset, save_dataset, save_cluster_labels\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from data_preprocessor import DataPreprocessor\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans, AgglomerativeClustering, BisectingKMeans, DBSCAN\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "cell_type": "markdown",
   "id": "c78e6b2511ae4d27",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "4e165449a3c30d28",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:10.130212Z",
     "start_time": "2024-05-23T23:55:10.007594Z"
    }
   },
   "source": "data_original = load_dataset(\"../data/assignment3_articles.xlsx\")",
   "outputs": [],
   "execution_count": 82
  },
  {
   "cell_type": "markdown",
   "id": "db16e4e109a979a7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1) Data Inspection and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e699f54b26baa87",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "First, we do some basic inspection of the dataset, such as checking the first few rows, the data types, the amount of missing values, and the value counts of certain columns."
   ]
  },
  {
   "cell_type": "code",
   "id": "ceefc662128d139d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:10.135072Z",
     "start_time": "2024-05-23T23:55:10.130715Z"
    }
   },
   "source": "data_original",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      index                                          headlines  \\\n",
       "0         0  Rupee ends 1 paisa lower at 83.38 against US d...   \n",
       "1         1  India vs Syria Live Streaming, AFC Asian Cup 2...   \n",
       "2         2  PM Modi to interact with VCs, teachers, studen...   \n",
       "3         3  How to remove bloatware apps from Samsung, Rea...   \n",
       "4         4  NEET SS 2023 result declared; counselling sche...   \n",
       "...     ...                                                ...   \n",
       "2495   2495  Google Search and Lens can now visualise STEM ...   \n",
       "2496   2496  Arsenal’s Partey an injury doubt as Arteta rel...   \n",
       "2497   2497  iQOO 12 will get 3 Android updates, will not h...   \n",
       "2498   2498  Lava Blaze Pro 5G review: Is this the best 5G ...   \n",
       "2499   2499  Karan Johar breaks down economics of cinema, r...   \n",
       "\n",
       "                                            description  \\\n",
       "0     Besides, selling pressure in the domestic equi...   \n",
       "1     AFC Asian Cup Live Streaming, India vs Syria F...   \n",
       "2     G20 University Connect: The commission has ask...   \n",
       "3     Smartphone companies often ship Android phones...   \n",
       "4     NEET SS 2023 Result: Candidates who appeared f...   \n",
       "...                                                 ...   \n",
       "2495  Google Search and Lens can now help students w...   \n",
       "2496  Partey came off at halftime during Arsenal's F...   \n",
       "2497  iQOO says its upcoming flagship phone, running...   \n",
       "2498  Lava Blaze Pro 5G is an excellent 5G smartphon...   \n",
       "2499  Filmmaker Karan Johar spoke about the business...   \n",
       "\n",
       "                                                content  \n",
       "0     The rupee consolidated in a narrow range and s...  \n",
       "1     India vs Syria AFC Asia Cup Live Streaming Det...  \n",
       "2     The University Grants Commission (UGC) is orga...  \n",
       "3     Smartphone manufacturers often pack new Androi...  \n",
       "4     The National Board of Examinations Medical Sci...  \n",
       "...                                                 ...  \n",
       "2495  Google has been consistently improving its Sea...  \n",
       "2496  Arsenal midfielder Thomas Partey is still an i...  \n",
       "2497  iQOO is all set to launch its upcoming flagshi...  \n",
       "2498  In less than a year, India has accounted for o...  \n",
       "2499  Film production as a business is rife with ris...  \n",
       "\n",
       "[2500 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>headlines</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Rupee ends 1 paisa lower at 83.38 against US d...</td>\n",
       "      <td>Besides, selling pressure in the domestic equi...</td>\n",
       "      <td>The rupee consolidated in a narrow range and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>India vs Syria Live Streaming, AFC Asian Cup 2...</td>\n",
       "      <td>AFC Asian Cup Live Streaming, India vs Syria F...</td>\n",
       "      <td>India vs Syria AFC Asia Cup Live Streaming Det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PM Modi to interact with VCs, teachers, studen...</td>\n",
       "      <td>G20 University Connect: The commission has ask...</td>\n",
       "      <td>The University Grants Commission (UGC) is orga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>How to remove bloatware apps from Samsung, Rea...</td>\n",
       "      <td>Smartphone companies often ship Android phones...</td>\n",
       "      <td>Smartphone manufacturers often pack new Androi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NEET SS 2023 result declared; counselling sche...</td>\n",
       "      <td>NEET SS 2023 Result: Candidates who appeared f...</td>\n",
       "      <td>The National Board of Examinations Medical Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2495</td>\n",
       "      <td>Google Search and Lens can now visualise STEM ...</td>\n",
       "      <td>Google Search and Lens can now help students w...</td>\n",
       "      <td>Google has been consistently improving its Sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>2496</td>\n",
       "      <td>Arsenal’s Partey an injury doubt as Arteta rel...</td>\n",
       "      <td>Partey came off at halftime during Arsenal's F...</td>\n",
       "      <td>Arsenal midfielder Thomas Partey is still an i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>2497</td>\n",
       "      <td>iQOO 12 will get 3 Android updates, will not h...</td>\n",
       "      <td>iQOO says its upcoming flagship phone, running...</td>\n",
       "      <td>iQOO is all set to launch its upcoming flagshi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2498</td>\n",
       "      <td>Lava Blaze Pro 5G review: Is this the best 5G ...</td>\n",
       "      <td>Lava Blaze Pro 5G is an excellent 5G smartphon...</td>\n",
       "      <td>In less than a year, India has accounted for o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2499</td>\n",
       "      <td>Karan Johar breaks down economics of cinema, r...</td>\n",
       "      <td>Filmmaker Karan Johar spoke about the business...</td>\n",
       "      <td>Film production as a business is rife with ris...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "id": "698a43f7eb28c035",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:10.165778Z",
     "start_time": "2024-05-23T23:55:10.161075Z"
    }
   },
   "source": "data_original.info()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2500 entries, 0 to 2499\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   index        2500 non-null   int64 \n",
      " 1   headlines    2500 non-null   object\n",
      " 2   description  2500 non-null   object\n",
      " 3   content      2500 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "markdown",
   "id": "ab716292afe78ac0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Preprocessing the text data"
   ]
  },
  {
   "cell_type": "code",
   "id": "ec8602ce3f498caa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:10.207262Z",
     "start_time": "2024-05-23T23:55:10.204827Z"
    }
   },
   "source": [
    "# Initialize the DataPreprocessor object\n",
    "preprocessor = DataPreprocessor()"
   ],
   "outputs": [],
   "execution_count": 85
  },
  {
   "cell_type": "markdown",
   "id": "e8b6fa7195b612d2",
   "metadata": {},
   "source": [
    "We quickly how below how the preprocessor works by applying it to the first row of the content column."
   ]
  },
  {
   "cell_type": "code",
   "id": "cc307f3a88c5515e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:10.371604Z",
     "start_time": "2024-05-23T23:55:10.368983Z"
    }
   },
   "source": [
    "# get first row and last column\n",
    "data_original.iloc[0, -1]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The rupee consolidated in a narrow range and settled 1 paisa lower at 83.38 (provisional) against the US dollar on Tuesday, as investors preferred to remain cautious ahead of the domestic inflation data release and upcoming US Fed meeting.\\nBesides, selling pressure in the domestic equity markets dented market sentiments, forex traders said.\\nHowever, a weaker American currency against major currencies overseas restricted the loss in the local currency, they added.\\nADVERTISEMENT\\nAt the interbank foreign exchange market, the local unit opened at 83.36 and settled at 83.38 (provisional) against the greenback, registering a loss of 1 paisa from its previous close.\\nDuring intra-day, the rupee touched a high of 83.35 and hit the lowest level of 83.39.\\nOn Monday, the domestic currency settled at 83.37 against the US dollar.\\nInvestors largely remained concerned over the domestic inflation data as well as industrial production numbers to be announced later in the day.\\nADVERTISEMENT\\nCurrency traders were also awaiting the US Federal Reserve’s monetary policy decision likely to be announced later this week.\\n“The upcoming focus is on the US CPI data in the evening, with expectations of 0.3 per cent on a month-on-month basis and a lower year-on-year figure at 3.1 per cent. Anticipating mixed reactions, the rupee seems unaffected, persisting within the broad range of 83.30-83.45,” Jateen Trivedi, VP Research Analyst at LKP Securities, said.\\nMeanwhile, the dollar index, which gauges the greenback’s strength against a basket of six currencies, was trading 0.28 per cent lower at 103.41 on Tuesday.\\nADVERTISEMENT\\nBrent crude futures, the global oil benchmark, advanced 0.34 per cent to USD 76.29 per barrel.\\nOn the domestic equity market front, the 30-share benchmark BSE Sensex plunged 377.50 points, or 0.54 per cent, to settle at 69,551.03 points. The Nifty also fell 90.70 points, or 0.43 per cent, to 20,906.40 points.\\nForeign Institutional Investors (FIIs) were net buyers in the capital market on Monday as they bought shares worth Rs 1,261.13 crore, according to exchange data.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "id": "453d5e7cc1fdf00a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:10.483103Z",
     "start_time": "2024-05-23T23:55:10.478616Z"
    }
   },
   "source": "preprocessor.preprocess_text(data_original.iloc[0, -1])",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rupe consolid narrow rang settl paisa lower provision us dollar tuesday investor prefer remain cautiou ahead domest inflat data releas upcom us fed meet besid sell pressur domest equiti market dent market sentiment forex trader said howev weaker american currenc major currenc oversea restrict loss local currenc ad interbank foreign exchang market local unit open settl provision greenback regist loss paisa previou close intraday rupe touch high hit lowest level monday domest currenc settl us dollar investor larg remain concern domest inflat data well industri product number announc later day currenc trader also await us feder reserv monetari polici decis like announc later week upcom focu us cpi data even expect per cent monthonmonth basi lower yearonyear figur per cent anticip mix reaction rupe seem unaffect persist within broad rang jateen trivedi vp research analyst lkp secur said meanwhil dollar index gaug greenback strength basket six currenc trade per cent lower tuesday brent crude futur global oil benchmark advanc per cent usd per barrel domest equiti market front benchmark bse sensex plung point per cent settl point nifti also fell point per cent point foreign institut investor fii net buyer capit market monday bought share worth rs crore accord exchang data'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "markdown",
   "id": "7e178fc5a42adcb4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "id": "74f30def8a10fd8e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:10.665893Z",
     "start_time": "2024-05-23T23:55:10.661715Z"
    }
   },
   "source": [
    "def count_numbers(text):\n",
    "    \"\"\"\n",
    "    Count the occurrences of numbers in the text.\n",
    "    \"\"\"\n",
    "    # match numbers\n",
    "    pattern = r'\\b\\d+[,.]\\d+\\b|\\b\\d+[,.]?\\b|\\b[,.]\\d+\\b'\n",
    "    return len(re.findall(pattern, text))\n",
    "\n",
    "def count_integers(text):\n",
    "    \"\"\"\n",
    "    Count the occurrences of integers in the text.\n",
    "    \"\"\"\n",
    "    # match integers\n",
    "    pattern = r'(?<![\\.,])\\b\\d+\\b(?![\\.,])'\n",
    "    return len(re.findall(pattern, text))\n",
    "\n",
    "def count_floats(text):\n",
    "    \"\"\"\n",
    "    Count the occurrences of floating point numbers in the text.\n",
    "    \"\"\"\n",
    "    # match floating point numbers\n",
    "    pattern = r'\\b\\d+[\\.,]\\d+\\b'\n",
    "    return len(re.findall(pattern, text))\n",
    "\n",
    "def preprocess_col(preprocessor: DataPreprocessor, col: pd.Series, h_pct: float = 0, l_pct: float = 0) -> pd.Series:\n",
    "    \"\"\" \n",
    "    Preprocesses a column of text data using the preprocessor (cfr. data_preprocessor.py), \n",
    "    and by removing the top $h_pct of the most frequent words and the top $l_pct of the least frequent words.\n",
    "    \n",
    "    Inspired partly by: https://medium.com/analytics-vidhya/introduction-to-text-classification-in-python-659eccf6b2e\n",
    "    \n",
    "    :param preprocessor: preprocessor object\n",
    "    :param col: column of text data\n",
    "    :param h_pct: \"the percentage of high frequency words to remove from the corpus\"\n",
    "    :param l_pct: \"the percentage of low frequency words to remove from the corpus\"\n",
    "    :return: preprocessed column\n",
    "    \"\"\"\n",
    "\n",
    "    col = col.apply(preprocessor.preprocess_text)\n",
    "    \n",
    "    if h_pct != 0:\n",
    "        #removing the top $h_pct of the most frequent words \n",
    "        high_freq = pd.Series(' '.join(col).split()).value_counts()[:int(pd.Series(' '.join(col).split()).count()*h_pct/100)]\n",
    "        rem_high = col.apply(lambda x: \" \".join(x for x in x.split() if x not in high_freq))\n",
    "    else:\n",
    "        rem_high = col\n",
    "    \n",
    "    if l_pct != 0:\n",
    "        #removing the top $l_pct of the least frequent words\n",
    "        low_freq = pd.Series(' '.join(rem_high).split()).value_counts()[:-int(pd.Series(' '.join(rem_high).split()).count()*l_pct/100):-1]\n",
    "        rem_low = rem_high.apply(lambda x: \" \".join(x for x in x.split() if x not in low_freq))\n",
    "    else:\n",
    "        rem_low = rem_high\n",
    "    \n",
    "    return rem_low"
   ],
   "outputs": [],
   "execution_count": 88
  },
  {
   "cell_type": "markdown",
   "id": "56bb6b7c27aab568",
   "metadata": {},
   "source": [
    "We concatenate the headlines, descriptions, and preprocessed content columns into a single column, and preprocess the concatenated column."
   ]
  },
  {
   "cell_type": "code",
   "id": "f993d796da3ed5d4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:15.517424Z",
     "start_time": "2024-05-23T23:55:10.718396Z"
    }
   },
   "source": [
    "data = data_original.copy()\n",
    "# count amount of numbers in content column\n",
    "data['amount_of_integers'] = data['content'].apply(count_integers)\n",
    "data['amount_of_floats'] = data['content'].apply(count_floats)\n",
    "\n",
    "# remove news site subscriber stuff, I got this from Inte Vleminckx. We were in call while he was going through the dataset for these:\n",
    "\n",
    "data = data.replace(\"\"\"Register to read more stories\n",
    "Continue With:-\n",
    "Google\n",
    "Facebook\n",
    "Email\n",
    "Already have an account? Sign in\"\"\", '')\n",
    "data = data.replace('Click for more updates and latest Bollywood news along with Entertainment updates. Also get latest news and top headlines from India and around the world at The Indian Express.', '')\n",
    "data = data.replace(\"\"\"(‘My dear students’, a fortnightly column that is a conversation with young minds on current events, books, popular culture — just about anything that’s worth talking over a cup of coffee.)\n",
    "My dear students,\n",
    "This story is subscriber only!\n",
    "\n",
    "Now subscribe at a special discount of 15% Use Code: ELECTION15\n",
    "Subscribe Now\n",
    "Already a subscriber? Sign in\"\"\", '')\n",
    "data = data.replace(\"\"\"This premium article is free for now..\n",
    "Register to continue reading.\n",
    "Register\"\"\", '')\n",
    "data = data.replace('Already a subscriber? Sign in', '')\n",
    "data = data.replace('Already have an account? Sign in', '')\n",
    "data = data.replace('You have exhausted your monthly limit of free stories.', '')\n",
    "data = data.replace('CLICK HERE FOR MORE', '')\n",
    "data = data.replace('BUY NOW', '')\n",
    "data['content'] = data['content'].replace('Register', '')\n",
    "\n",
    "data['preprocessed_content'] = preprocess_col(preprocessor, data['content'], h_pct=1, l_pct=1)\n",
    "data['concatenated'] = data['headlines'] + ' ' + data['description'] + ' ' + data['preprocessed_content']\n",
    "data['preprocessed_concat'] = preprocess_col(preprocessor, data['concatenated'], h_pct=0, l_pct=0)\n",
    "\n",
    "data_preprocessed = data.drop(columns=['headlines', 'description', 'content', 'preprocessed_content', 'concatenated'])"
   ],
   "outputs": [],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "id": "af581ce3e32d3832",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:15.521980Z",
     "start_time": "2024-05-23T23:55:15.517928Z"
    }
   },
   "source": [
    "data_preprocessed"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      index  amount_of_integers  amount_of_floats  \\\n",
       "0         0                   3                21   \n",
       "1         1                   4                 0   \n",
       "2         2                   3                 0   \n",
       "3         3                   0                 0   \n",
       "4         4                   2                 0   \n",
       "...     ...                 ...               ...   \n",
       "2495   2495                   0                 0   \n",
       "2496   2496                   1                 0   \n",
       "2497   2497                   9                 0   \n",
       "2498   2498                   1                 0   \n",
       "2499   2499                   1                 0   \n",
       "\n",
       "                                    preprocessed_concat  \n",
       "0     rupe end paisa lower us dollar besid sell pres...  \n",
       "1     india vs syria live stream afc asian cup watch...  \n",
       "2     pm modi interact vc teacher student ugc univer...  \n",
       "3     remov bloatwar app samsung realm xiaomi vivo r...  \n",
       "4     neet ss result declar counsel schedul soon nat...  \n",
       "...                                                 ...  \n",
       "2495  googl search len visualis stem model help calc...  \n",
       "2496  arsen partey injuri doubt arteta reli jorginho...  \n",
       "2497  iqoo get android updat hot app hot game iqoo s...  \n",
       "2498  lava blaze pro review best phone rs lava blaze...  \n",
       "2499  karan johar break econom cinema reveal busi mo...  \n",
       "\n",
       "[2500 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>amount_of_integers</th>\n",
       "      <th>amount_of_floats</th>\n",
       "      <th>preprocessed_concat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>rupe end paisa lower us dollar besid sell pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>india vs syria live stream afc asian cup watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>pm modi interact vc teacher student ugc univer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>remov bloatwar app samsung realm xiaomi vivo r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>neet ss result declar counsel schedul soon nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>googl search len visualis stem model help calc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>2496</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>arsen partey injuri doubt arteta reli jorginho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>2497</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>iqoo get android updat hot app hot game iqoo s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2498</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>lava blaze pro review best phone rs lava blaze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2499</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>karan johar break econom cinema reveal busi mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 90
  },
  {
   "cell_type": "markdown",
   "id": "73e791189f8c617b",
   "metadata": {},
   "source": [
    "We vectorize the preprocessed text data using the TF-IDF method."
   ]
  },
  {
   "cell_type": "code",
   "id": "ddab4a1d095c73e8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:15.640789Z",
     "start_time": "2024-05-23T23:55:15.522482Z"
    }
   },
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5)\n",
    "# vectorizer = CountVectorizer()\n",
    "vectorized_data = vectorizer.fit_transform(data_preprocessed['preprocessed_concat']) # Vectorize preprocessed text data\n",
    "vectorized_data_df = pd.DataFrame(vectorized_data.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "tfidf_features = vectorized_data_df.copy()"
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:15.643202Z",
     "start_time": "2024-05-23T23:55:15.641291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# number_of_integers_scaled = scaler.fit_transform(data_preprocessed[['amount_of_integers']])\n",
    "# number_of_floats_scaled = scaler.fit_transform(data_preprocessed[['amount_of_floats']])\n",
    "# Combine TF-IDF features with the normalized count columns\n",
    "# combined_features = np.hstack((tfidf_features, number_of_integers_scaled, number_of_floats_scaled))\n",
    "# tfidf_features = pd.DataFrame(combined_features, columns=list(vectorizer.get_feature_names_out()) + ['amount_of_integers', 'amount_of_floats'])"
   ],
   "id": "424cc5340bad9798",
   "outputs": [],
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "id": "c116290ca9b24b78",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:15.657372Z",
     "start_time": "2024-05-23T23:55:15.643705Z"
    }
   },
   "source": [
    "tfidf_features"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      aaa  aamir   ab  abandon  abc  abhishek  abil  abl  abraham  abrar  ...  \\\n",
       "0     0.0    0.0  0.0      0.0  0.0       0.0   0.0  0.0      0.0    0.0  ...   \n",
       "1     0.0    0.0  0.0      0.0  0.0       0.0   0.0  0.0      0.0    0.0  ...   \n",
       "2     0.0    0.0  0.0      0.0  0.0       0.0   0.0  0.0      0.0    0.0  ...   \n",
       "3     0.0    0.0  0.0      0.0  0.0       0.0   0.0  0.0      0.0    0.0  ...   \n",
       "4     0.0    0.0  0.0      0.0  0.0       0.0   0.0  0.0      0.0    0.0  ...   \n",
       "...   ...    ...  ...      ...  ...       ...   ...  ...      ...    ...  ...   \n",
       "2495  0.0    0.0  0.0      0.0  0.0       0.0   0.0  0.0      0.0    0.0  ...   \n",
       "2496  0.0    0.0  0.0      0.0  0.0       0.0   0.0  0.0      0.0    0.0  ...   \n",
       "2497  0.0    0.0  0.0      0.0  0.0       0.0   0.0  0.0      0.0    0.0  ...   \n",
       "2498  0.0    0.0  0.0      0.0  0.0       0.0   0.0  0.0      0.0    0.0  ...   \n",
       "2499  0.0    0.0  0.0      0.0  0.0       0.0   0.0  0.0      0.0    0.0  ...   \n",
       "\n",
       "      youll  young  youngest  your  youth  youtub  yrf  zealand  zero  zone  \n",
       "0       0.0    0.0       0.0   0.0    0.0     0.0  0.0      0.0   0.0   0.0  \n",
       "1       0.0    0.0       0.0   0.0    0.0     0.0  0.0      0.0   0.0   0.0  \n",
       "2       0.0    0.0       0.0   0.0    0.0     0.0  0.0      0.0   0.0   0.0  \n",
       "3       0.0    0.0       0.0   0.0    0.0     0.0  0.0      0.0   0.0   0.0  \n",
       "4       0.0    0.0       0.0   0.0    0.0     0.0  0.0      0.0   0.0   0.0  \n",
       "...     ...    ...       ...   ...    ...     ...  ...      ...   ...   ...  \n",
       "2495    0.0    0.0       0.0   0.0    0.0     0.0  0.0      0.0   0.0   0.0  \n",
       "2496    0.0    0.0       0.0   0.0    0.0     0.0  0.0      0.0   0.0   0.0  \n",
       "2497    0.0    0.0       0.0   0.0    0.0     0.0  0.0      0.0   0.0   0.0  \n",
       "2498    0.0    0.0       0.0   0.0    0.0     0.0  0.0      0.0   0.0   0.0  \n",
       "2499    0.0    0.0       0.0   0.0    0.0     0.0  0.0      0.0   0.0   0.0  \n",
       "\n",
       "[2500 rows x 4312 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aamir</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abhishek</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abraham</th>\n",
       "      <th>abrar</th>\n",
       "      <th>...</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>youngest</th>\n",
       "      <th>your</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yrf</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 4312 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "id": "1454374be7371c03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:17.232012Z",
     "start_time": "2024-05-23T23:55:15.657874Z"
    }
   },
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Fit LDA model\n",
    "n_topics = 5  # Number of topics to extract\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda.fit(vectorized_data)\n",
    "\n",
    "# Get the topic distribution for each document\n",
    "topic_distribution = lda.transform(vectorized_data)\n",
    "d = data.copy()\n",
    "d['topic'] = np.argmax(topic_distribution, axis=1)"
   ],
   "outputs": [],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "id": "979f23a1490e6e74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:17.235710Z",
     "start_time": "2024-05-23T23:55:17.232515Z"
    }
   },
   "source": [
    "d['topic'].value_counts()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "2    811\n",
       "1    681\n",
       "0    382\n",
       "3    377\n",
       "4    249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "id": "8d16f27193c9b8c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:17.243082Z",
     "start_time": "2024-05-23T23:55:17.236212Z"
    }
   },
   "source": [
    "# Print the top words for each topic\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic #{topic_idx}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "n_top_words = 20\n",
    "print(\"Topics in LDA model:\")\n",
    "tf_feature_names = vectorizer.get_feature_names_out()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)\n",
    "\n",
    "# Count the number of articles for each topic\n",
    "topic_counts = d['topic'].value_counts()\n",
    "print(\"Number of articles per topic:\")\n",
    "print(topic_counts)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics in LDA model:\n",
      "Topic #0:\n",
      "test vs cuet australia india cricket world kohli ind khan cup team au virat play run women pakistan first sharma\n",
      "Topic #1:\n",
      "rs per cent crore india market share point tech new us news sensex price galaxi bank launch trade watch sale\n",
      "Topic #2:\n",
      "exam result student ug univers offici check websit class neet candid year board releas india iit jee counsel programm new\n",
      "Topic #3:\n",
      "film shah rukh khan box collect offic day kapoor ai rs anim dunki crore salaar ranbir new director year make\n",
      "Topic #4:\n",
      "kapoor khan boss india bigg gold fund say anim watch ranbir said game nanda rs mandanna ira video ankita bank\n",
      "\n",
      "Number of articles per topic:\n",
      "topic\n",
      "2    811\n",
      "1    681\n",
      "0    382\n",
      "3    377\n",
      "4    249\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "id": "5c15dab35506fa78",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Clustering"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T23:55:17.245727Z",
     "start_time": "2024-05-23T23:55:17.243586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RANDOM_STATE = 42\n",
    "DIM_REDUCTION_COMPONENTS = 20\n",
    "MAX_K = 12\n",
    "STATISTICS_N_PERMUTATIONS = 10\n",
    "NUM_CLUSTERS = 5 # set after elbow method and others"
   ],
   "id": "53f887bc51302932",
   "outputs": [],
   "execution_count": 97
  },
  {
   "cell_type": "markdown",
   "id": "455b3dc1f6b4abc6",
   "metadata": {},
   "source": [
    "### Expectation Maximization"
   ]
  },
  {
   "cell_type": "code",
   "id": "71a32f98035ffa17",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# tfidf_features = vectorized_data_df\n",
    "# num_clusters = 5\n",
    "# em = GaussianMixture(n_components=num_clusters, random_state=42, max_iter=20)\n",
    "# em.fit(tfidf_features)\n",
    "# cluster_labels = em.predict(tfidf_features)\n",
    "# \n",
    "# # Evaluate clustering using silhouette score\n",
    "# silhouette_avg = silhouette_score(tfidf_features, cluster_labels)\n",
    "# print(\"Silhouette Score:\", silhouette_avg)\n",
    "# print(\"BIC:\", em.bic(tfidf_features))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "272cf7e6fa215f5c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def plot_bic_aic(text_data, max_components=10):\n",
    "    bic = []\n",
    "    aic = []\n",
    "    n_components_range = range(1, max_components + 1)\n",
    "    \n",
    "    for n_components in n_components_range:\n",
    "        gmm = GaussianMixture(n_components=n_components, random_state=42)\n",
    "        gmm.fit(text_data.toarray())\n",
    "        bic.append(gmm.bic(text_data.toarray()))\n",
    "        aic.append(gmm.aic(text_data.toarray()))\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(n_components_range, bic, marker='o', label='BIC')\n",
    "    plt.xlabel('Number of components')\n",
    "    plt.ylabel('BIC')\n",
    "    plt.title('BIC vs. Number of components')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(n_components_range, aic, marker='o', label='AIC')\n",
    "    plt.xlabel('Number of components')\n",
    "    plt.ylabel('AIC')\n",
    "    plt.title('AIC vs. Number of components')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# plot_bic_aic(text, max_components=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eb788edf091a6aad",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def cross_val_log_likelihood(text_data, max_components=10):\n",
    "    n_components_range = range(1, max_components + 1)\n",
    "    log_likelihoods = []\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for n_components in n_components_range:\n",
    "        gmm = GaussianMixture(n_components=n_components, random_state=42)\n",
    "        log_likelihood = 0\n",
    "        \n",
    "        for train_index, test_index in skf.split(text_data, np.zeros(text_data.shape[0])):\n",
    "            gmm.fit(text_data[train_index].toarray())\n",
    "            log_likelihood += gmm.score(text_data[test_index].toarray())\n",
    "        \n",
    "        log_likelihoods.append(log_likelihood / skf.n_splits)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(n_components_range, log_likelihoods, marker='o')\n",
    "    plt.xlabel('Number of components')\n",
    "    plt.ylabel('Log-Likelihood')\n",
    "    plt.title('Log-Likelihood vs. Number of components')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# cross_val_log_likelihood(text, max_components=10)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
